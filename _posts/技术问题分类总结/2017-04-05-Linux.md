---
layout: post
title:  "Linux"
date: 2017-04-05 00:00:04
categories: 技术问题分类总结
tags: Linux
excerpt: ""
---

* content
{:toc}

## IO阻塞、非阻塞、同步、异步
**同步和异步**
同步和异步是**针对应用程序和内核的交互而言**的，同步指的是用户进程触发I/O操作并等待或者轮询的去查看I/O操作是否就绪，而异步是指用户进程触发I/O操作以后便开始做自己的事情，而当I/O操作已经完成的时候会得到I/O完成的通知。

**阻塞和非阻塞**
阻塞和非阻塞是**针对于进程在访问数据的时候**，根据I/O操作的就绪状态来采取的不同方式，是一种读取或者写入函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。

**服务器IO模型**
* 阻塞式模型（blocking IO）
大部分的socket接口都是阻塞型的（ listen()、accpet()、send()、recv() 等）。阻塞型接口是指系统调用（一般是 IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。在线程被阻塞期间，线程将无法执行任何运算或响应任何的网络请求，这给多客户机、多业务逻辑的网络编程带来了挑战。
  ![image](/images/tech/basic_9.png)

* 多线程的服务器模型（Multi-Thread）
应对多客户机的网络应用，最简单的解决方式是在服务器端使用多线程（或多进程）。多线程（或多进程）的目的是**让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接**。但是如果要同时响应成千上万路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率。
在多线程的基础上，可以考虑使用线程池或连接池，线程池旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。连接池维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统。

* 非阻塞式模型（Non-blocking IO）
相比于阻塞型接口的显著差异在于，在被调用之后立即返回。
  ![image](/images/tech/basic_10.png)
需要应用程序调用许多次来等待操作完成。这可能效率不高，因为在很多情况下，当内核执行这个命令时，应用程序必须要进行**忙碌等待**，直到数据可用为止。
另一个问题，在循环调用非阻塞IO的时候，将大幅度占用CPU，所以一般使用select等来检测是否可以操作。

* 多路复用IO（IO multiplexing）
支持I/O复用的系统调用有select、poll、epoll、kqueue等。使用select返回后，仍然需要轮询再检测每个socket的状态（读、写），这样的轮询检测在大量连接下也是效率不高的。因为**当需要探测的句柄值较大时，select () 接口本身需要消耗大量时间去轮询各个句柄**。
很多操作系统提供了更为高效的接口，如Linux 提供了`epoll`，BSD提供了`kqueue`，Solaris提供了`/dev/poll `…。如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐，能显著**提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率**。
  ![image](/images/tech/basic_11.png)

* 使用事件驱动库libevent的服务器模型
libevent是一个**事件触发的**网络库，适用于Windows、Linux、BSD等多种平台，**内部使用select、epoll、kqueue、IOCP等系统调用管理事件机制**。
libevent库提供一种事件机制，它作为底层网络后端的包装器。事件系统让为连接添加处理函数变得非常简便，同时降低了底层IO复杂性。这是libevent系统的核心。
创建libevent服务器的基本方法是，注册当发生某一操作（比如接受来自客户端的连接）时应该执行的函数，然后调用主事件循环event_dispatch()。执行过程的控制现在由libevent系统处理。注册事件和将调用的函数之后，事件系统开始自治；在应用程序运行时，可以在事件队列中添加（注册）或 删除（取消注册）事件。事件注册非常方便，可以通过它添加新事件以处理新打开的连接，从而构建灵活的网络处理系统。

* 信号驱动IO模型（Signal-driven IO）
让内核在描述符就绪时发送SIGIO信号通知应用程序。
  ![image](/images/tech/basic_12.png)

* 异步IO模型（asynchronous IO）
告知内核启动某个操作，并让内核在整个操作（包括将数据从内核复制到用户的缓冲区）完成后通知用户。这种模型与信号驱动模型的主要区别在于：信号驱动式I/O是由内核通知何时可以启动一个I/O操作，而异步I/O模型是由内核通知I/O操作何时完成。
  ![image](/images/tech/basic_13.png)

**异步IO与同步IO的区别**
A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;
An asynchronous I/O operation does not cause the requesting process to be blocked; 
两者的区别就在于synchronous IO做IO operation的时候会将process阻塞。按照这个定义阻塞、非阻塞、IO多路复用其实都属于同步IO。

**异步IO与非阻塞IO的区别**
在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用`recvfrom`来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程**将整个IO操作（分为两步：准备数据、将数据从内核复制到用户空间）交给了他人（kernel）完成，然后他人做完后发信号通知**。在此期间，用户进程**不需要去检查IO操作的状态，也不需要主动的去拷贝数据**。

## select、poll、epoll
**文件描述符（fd）**
**文件描述符是一个简单的整数**，用以标明每一个**被进程所打开的文件和socket的索引**。第一个打开的文件是0，第二个是1，依此类推。最前面的三个文件描述符（0、1、2）分别与标准输入（stdin），标准输出（stdout）和标准错误（stderr）对应。**Unix操作系统通常给每个进程能打开的文件数量强加一个限制**。当用完所有的文件描述符后，将不能接收用户新的连接，直到一部分当前请求完成，相应的文件和socket被关闭。

**IO多路复用技术**

select，poll，epoll都是IO多路复用的机制。I/O多路复用通过一种机制，可以**监视多个文件描述符**，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**select、poll、epoll本质上都是同步I/O，因为它们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间**。

**epoll的改进**

* **select、poll需要自己不断轮询所有fd集合**，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是**select和poll在醒着的时候要遍历整个fd集合，而epoll在醒着的时候只要判断一下就绪链表是否为空就行了**，这节省了大量的CPU时间。这就是**回调机制带来的性能提升**（本质的改进在于epoll采用基于事件的就绪通知方式）。
* select、poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。（本质的改进就是使用了**内存映射**（mmap）技术）

epoll被公认为Linux2.6下性能最好的多路I/O就绪通知方法，**实现高效处理百万句柄**。

## nohup与&的区别
最直观的区别：
使用&执行的命令，要是关闭终端（将发出SIGHUP信号），命令会停止。而使用nohup执行的命令，既使把终端关了，命令仍然会继续运行。
nohup执行的命令会**忽略所有挂断（SIGHUP）信号**。
一般结合使用：nohup command & 

## 启动Linux守护进程的方法
**Linux进程类型**
Linux操作系统包括如下3种不同类型的进程，每种进程都有其自己的特点和属性。
* **交互进程**：由shell启动的进程。可在前台运行，也可在后台运行；
* **批处理进程**：一个进程序列；
* **守护进程**：守护进程是指在后台运行而又没有启动终端或登录shell。守护进程一般由系统开机时通过脚本自动激活启动或者由root用户通过shell启动。守护进程总是活跃的，一般在后台运行，所以它所处的状态是等待处理任务的请求。

**启动守护进程有如下几种方法**
* 在引导系统时启动：通过脚本启动，这些脚本一般位于`/etc/rc.d`中。在/etc目录下的很多rc文件都是启动脚本 。rc0.d、rc1.d、rc2.d、rc3.d、rc4.d、rc5.d、rc6.d，其中的数字代表在指定的runlevel下运行相应的描述，0代表关机，6代表重启。其中，以k开头的文件表示关闭，以s开头的文件表示重启。可查看相应文件夹中的readme文件。rc0.d、rc1.d、rc2.d、rc3.d、rc4.d、rc5.d、rc6.d、rcS.d都连接到`/etc/init.d`文件夹，**该目录中存放着守护进程的运行文件**。
* 人工手动从shell提示符启动：**任何具有权限的用户都可以启动相应的守护进程**。
```
# 启动FTP服务器，ubuntu下默认已经安装了vsfptd服务器
root@Ubuntu:~# /etc/init.d/vsftpd start
```
* 使用crond守护进程启动
* 执行at命令启动

## 静态链接与动态链接比较
静态链接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，兼容性好，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。
动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。
现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。


## Linux中通过编译安装的方式安装程序的各步骤
源码要运行，必须先转成二进制的机器码。这是编译器的任务。
对于简单的代码，可以直接调用编译器生成二进制文件后运行，如：

```
$ gcc test.c
$ ./a.out
```
对于复杂的项目，编译过程通常分成3个部分：
```
$ ./configure
$ make  
$ make install
```

整个编译安装过程分为以下步骤：

* 配置
配置信息保存在一个配置文件之中，约定俗成是一个叫做`configure的`脚本文件。通常它是由**autoconf工具**生成的。**编译器通过运行这个脚本，获知编译参数**。如果用户的系统环境比较特别，或者有一些特定的需求，就需要手动向configure脚本提供编译参数，如：

```
# 指定安装后的文件保存在www目录，并且编译时加入mysql模块的支持
$ ./configure --prefix=/www --with-mysql  
```

* 确定标准库和头文件的位置
从配置文件中知道标准库和头文件的位置。

* 确定依赖关系

源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。假定A文件依赖于B文件，编译器应该保证：只有在B文件编译完成后，才开始编译A文件。且当B文件发生变化时，A文件会被重新编译。
**编译顺序保存在一个叫做`makefile`的文件中**，里面列出哪个文件先编译，哪个文件后编译。而**makefile文件由configure脚本运行生成**，这就是为什么编译时configure必须首先运行的原因。

* 预编译头文件
不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，**编译器会在编译源码之前，先编译头文件**。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。不过，并不是头文件的所有内容都会被预编译。用来声明宏的#define命令，就不会被预编译。

* 预处理
编译器就开始替换掉源码中的头文件和宏以及移除注释。

* 编译
编译器就**开始生成机器码**。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。这种转码后的文件称为对象文件（object file）。

* 链接
**把外部函数的代码（通常是后缀名为.lib和.a的文件）添加到可执行文件中**。这就叫做链接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做`静态连接`（static linking）
make命令的作用，就是从第（4）步头文件预编译开始，一直到做完这一步。

* 安装
**将可执行文件保存到用户事先指定的安装目录**。这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为安装（Installation）。

* 操作系统链接
以某种方式**通知操作系统，让其知道可以使用这个程序了**。这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在`/usr/share/applications`目录下的`.desktop`文件中。
make install命令，就用来完成安装和操作系统连接这两步。

* 生成安装包
将上一步生成的可执行文件，做成可以分发的安装包。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。

* 动态链接
开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。


## 进程通信的类型 
* 共享存储器系统(Shared-Memory System)
全局变量、共享数据结构、共享存储区

* 消息传递系统(Message passing system)
进程间的数据交换，是以格式化的消息(message)为单位的；在计算机网络中，又把message称为报文。

* 管道通信(Pipe)
管道是指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名pipe文件。向管道(共享文件)提供输入的发送进程(即写进程)， 以字符流形式将大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。

## 进程状态
在多进程程序系统中，进程在处理器上交替运行，在运行、就绪和阻塞3种基本状态之间不断地发生变化。由于进程的不断创建，系统资源（特别是主存资源）已不能满足进程运行的要求。此时就必须将某些进程挂起，对换到磁盘镜像区，暂时不参与进程调度，以平衡系统负载的目的。如果系统出现故障，或者是用户调试程序，也可能需要将进程挂起检查问题。
所谓挂起状态，**实际上就是一种静止的状态**。一个进程被挂起后，不管它是否在就绪状态，系统都不分配给它处理机（区别于阻塞状态）。这样**进程的三态模型**（执行、就绪、阻塞）就变为**五态模型**：执行状态、活动就绪状态、静止就绪状态、活动阻塞状态和静止阻塞状态 

* 活动就绪：指进程**在主存并且可被调度**的状态 （对应于三态的就绪状态）
* 静止就绪：指进程**被对换到辅存**时的就绪状态，是不能被直接调度的状态，只有当主存中没有活动就绪态进程，或者是挂起态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活动就绪。 
* 活动阻塞：指进程在主存中。**一旦等待的事件产生，便进入活动就绪状态**（对应于三态的阻塞状态） 
* 静止阻塞：指进程对换到辅存时的阻塞状态。**一旦等待的事件产生，便进入静止就绪状态**。


## Linux ext2和ext3文件系统的区别
**Linux文件系统**
Linux ext2/ext3文件系统**使用索引节点来记录文件信息**。索引节点是一个结构，它包含了一个文件的长度、创建及修改时间、权限、所属关系、磁盘中的位置等信息。**一个文件系统维护了一个索引节点的数组，每个文件或目录都与索引节点数组中的唯一一个元素对应**。系统给每个索引节点分配了一个号码，也就是该节点在数组中的索引号，称为**索引节点号**。

Linux文件系统将文件索引节点号和文件名同时保存在目录中。所以，**目录只是将文件的名称和它的索引节点号结合在一起的一张表**，目录中每一对文件名称和索引节点号称为一个`连接`。 **对于一个文件来说有唯一的索引节点号与之对应，对于一个索引节点号，却可以有多个文件名与之对应**。因此，在磁盘上的同一个文件可以通过不同的路径去访问它。
Linux缺省情况下使用的文件系统为ext2，ext2文件系统的确高效稳定。但是，随着Linux系统在关键业务中的应用，Linux文件系统的弱点也渐渐显露出来：其中系统缺省使用的**ext2文件系统是非日志文件系统**。这在关键行业的应用是一个致命的弱点。
ext3文件系统是直接从Ext2文件系统发展而来，目前ext3文件系统已经非常稳定可靠。它完全兼容ext2文件系统。用户可以平滑地过渡到一个日志功能健全的文件系统中来。这实际上了也是ext3日志文件系统初始设计的初衷。

**ext3日志文件系统的特点**

* 高可用性

系统使用了ext3文件系统后，即使在非正常关机后，系统也不需要检查文件系统。宕机发生后，恢复ext3文件系统的时间只要数十秒钟。

* 数据的完整性:

ext3文件系统能够极大地提高文件系统的完整性，避免了意外宕机对文件系统的破坏。在保证数据完整性方面，ext3文件系统有2种模式可供选择。其中之一就是**同时保持文件系统及数据的一致性**模式。采用这种方式，你永远不再会看到由于非正常关机而存储在磁盘上的垃圾文件。

* 文件系统的速度

尽管使用ext3文件系统时，有时在存储数据时可能要多次写数据，但是，**从总体上看来，ext3比ext2的性能还要好一些**。这是因为ext3的日志功能对磁盘的驱动器读写头进行了优化。所以，文件系统的读写性能较之ext2文件系统并来说，性能并没有降低。

* 数据转换

由ext2文件系统转换成ext3文件系统非常容易，只要简单地键入两条命令即可完成整个转换过程，用户不用花时间备份、恢复、格式化分区等。用一个ext3文件系统提供的小工具tune2fs，它可以将ext2文件系统轻松转换为ext3日志文件系统。另外，ext3文件系统可以不经任何更改，而直接加载成为ext2文件系统。

* 多种日志模式

ext3有多种日志模式，一种工作模式是对所有的文件数据及metadata（定义文件系统中数据的数据,即数据的数据）进行日志记录（data=journal模式）；另一种工作模式则是只对metadata记录日志，而不对数据进行日志记录，也即所谓data=ordered或者data=writeback模式。系统管理人员可以根据系统的实际工作要求，在系统的工作速度与文件数据的一致性之间作出选择。


## 乐观锁与悲观锁
**悲观锁**
`悲观锁`（Pessimistic Lock）每次去读数据的时候都认为数据会被其他任务修改，所以会上锁，这样其他任务想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁、表锁、读锁、写锁等，都是在做操作之前先上锁。

**乐观锁**
`乐观锁`（Optimistic Lock）每次去读数据的时候都认为别的任务不会修改，所以不会上锁，但是**在更新（写）的时候**会判断一下在此期间其他任务有没有去更新这个数据(可以使用版本号等机制）。**乐观锁适用于多读的应用类型**，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。

两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。


## 僵尸进程
任何一个子进程（init除外）在exit()之后，并非马上就消失掉，而是留下一个称为`僵尸进程`（Zombie）的数据结构，等待父进程处理。**这是每个子进程在结束时都要经过的阶段**。

如果子进程在exit()之后，父进程没有来得及处理，这时用`ps -el`命令就能看到子进程的状态是`Z`。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

**僵尸进程的危害**
由于子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。UNIX提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息，就可以得到。这种机制就是： 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息（包括进程号、退出状态、运行时间等）。直到父进程通过wait/waitpid来取时才释放。但这样就导致了问题，如果进程不调用wait/waitpid的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。此即为僵尸进程的危害，应当避免。


## 分页和分段
* **页是信息的物理单位**，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。**段则是信息的逻辑单位**，它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。 
* **页的大小固定且由系统决定**，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而**段的长度却不固定**，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
* **分页的作业地址空间是一维的**，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而**分段的作业地址空间则是二维的**，程序员在标识一个地址时，既需给出段名， 又需给出段内地址。

## 后台进程与守护进程
* 最直观的区别：**守护进程没有控制终端，而后台进程还有**。如通过命令`firefox &`在后台运行firefox，此时firefox虽然在后台运行，但是并没有脱离终端的控制，如果把终端关掉则firefox也会一起关闭。
* 后台进程的文件描述符继承自父进程，例如shell，所以它也可以在当前终端下显示输出数据。但是**守护进程自己变成进程组长**，其文件描述符号和控制终端没有关联，是控制台无关的。
* **守护进程肯定是后台进程，但后台进程不一定是守护进程**。基本上任何一个程序都可以后台运行，但守护进程是具有特殊要求的程序，比如它能够脱离自己的父进程，成为自己的会话组长等（这些需要在程序代码中显式地写出来）。

## 查看僵尸进程
`ps -el`，查看`S`状态：

* `Z`：僵尸进程
* `S`：休眠状态
* `D`：不可中断的休眠状态
* `R`：运行状态
* `T`：停止或跟踪状态

## 僵尸进程变为孤儿进程
父进程死后，僵尸进程成为"孤儿进程"，过继给1号进程init，init会负责清理僵尸进程。

## 查看Linux进程之间的关系
```
ps -o pid,pgid,ppid,comm | cat
```

输出：
```
PID  PGID  PPID COMMAND
3003  3003  2986 su
3004  3004  3003 bash
3423  3423  3004 ps
3424  3423  3004 cat
```

每个进程都会属于一个进程组(process group)，每个进程组中可以包含多个进程。进程组会有一个组长进程 (process group leader)，**组长进程的PID成为进程组的ID** (process group ID, PGID)，以识别进程组。`PID`为进程自身的ID，`PGID`为进程所在的进程组的ID， `PPID`为进程的父进程ID。

## 协程理解
**普通程序调用的执行方式**
子程序，或者称为函数，在所有语言中都是**层级调用**，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。
所以**子程序调用是通过栈实现的**，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。

**协程的执行方式**
**协程**
又称微线程，纤程。英文名Coroutine。
协程的调用和子程序不同。
协程看上去也是子程序，但执行过程中，**在子程序内部可中断**，然后转而执行别的子程序（是中断后执行，而不是函数调用其他的子程序），在适当的时候再返回来接着执行。

**优点**
**协程的特点在于是一个线程执行（所以不是多线程）**。优势就是极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，**没有线程切换的开销**，和多线程比，线程数量越多，协程的性能优势就越明显。另一个优势就是**不需要多线程的锁机制**，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

**缺点**
**无法利用多核资源**：协程的本质是个单线程，它不能同时将单个CPU的多个核用上，协程需要和进程配合才能运行在多CPU上。当然我们日常所编写的绝大部分应用都没有这个必要，除非是CPU密集型应用。
**进行阻塞操作会阻塞掉整个程序**：这一点和事件驱动一样，可以使用异步IO操作来解决。


## 死锁产生的四个必要条件
* **互斥条件**：一个资源每次只能被一个进程使用。
* **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
* **不剥夺条件**：进程已获得的资源，在未使用完之前，不能强行剥夺。
* **循环等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系。

这四个条件是死锁的必要条件。只要系统发生死锁，这些条件必然成立，而只要上述条件之
一不满足，就不会发生死锁。


## Linux用户身份切换
将一般用户变成root：
```
[test@test test]$ su
```

将身份变成username的身份:
```
[root @test /root ]# sudo [-u username] [command]
```
root可以执行test用户的指令，建立test的文件不需要root的密码仍可以执行root的工具，这时就可以使用sudo。由于执行root身份的工作时，输入的密码是用户的密码，而不是root的密码，所以可以减少root密码外泄的可能性。


## 查看系统负载
通过查看/proc/loadavg可以了解到运行队列的情况：
```
cat /proc/loadavg
1.63 0.48 0.21 10/200 17145
```
其中：
1.63 0.48 0.21是不同时间内（最近1分钟、5分钟、15分钟）的系统负载，是单位时间内运行队列中就绪等待的进程数的平均值，如果值为0，说明每个进程只要就绪后就可以马上获得CPU，无需等待，这时系统的响应速度最快。
10/200中的10代表此时运行队列中的进程个数，而200代表此时的进程总数。
17145代表最后创建的一个进程ID。
也可以通过top命令或者w命令来获得系统负载，它们其实仍然来自于/proc/loadavg。

## IOWait
指CPU空闲并且等待I/O操作完成的时间比例。


## DMA（Direct Memory Access）
一开始磁盘和内存之间的数据传输是由CPU控制的，即数据需要经过CPU存储转发，这种方式称为PIO。后来有了DMA（Direct Memory Access），可以不经过CPU而直接进行磁盘和内存的数据交换。CPU只需要向DMA控制器下达指令，让其处理数据传送，DMA控制器使用系统总线传输数据，完毕后再通知CPU。

## 同步阻塞I/O与同步非阻塞I/O
同步阻塞I/O指当进程调用某些涉及I/O操作的系统调用或函数库时（accept()、send()、recv()等），进程暂停，等待I/O操作完成后再继续运行。
同步非阻塞I/O的调用不会等待数据的就绪，如果数据不可读或者不可写，它会立即告诉进程。相比于阻塞I/O这种非阻塞I/O结合反复轮询来尝试数据是否就绪，最大的好处是便于在一个进程里同时处理多个I/O操作。缺点在于会花费大量的CPU时间，使得进程处于忙碌等待状态。
非阻塞I/O一般只对网络I/O有效，比如在socket的选项中设置O_NONBLOCK。

## 多路I/O就绪通知的各种实现
多路I/O就绪通知允许进程通过一种方法来同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只对这些文件描述符进行数据访问。
I/O就绪通知只是有助于快速获得就绪的文件描述符，当得知数据就绪后，就访问数据本身而言，仍然需要选择阻塞或者非阻塞的访问方式。

* select
监视包含多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符会被修改标志位使得进程可以获得这些文件描述符从而进行后续的读写操作。有点在于几乎所有平台都支持，缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上为1024，假如维持的连接已达上限，新的连接请求将被拒绝。此外，select所维护的数据结构复制开销较大，对于非活跃状态的TCP连接也会进行线性扫描等，也是缺陷。

* poll
本质上和select没有太大区别（实现者不同），包含大量文件描述符的数组被整体复制于用户态和内核态的地址空间，而不论这些文件描述符是否就绪，但是poll没有最大文件描述符的数量限制。

* SIGIO
通过实时信号来通知，不同于select/poll，对于变为就绪状态的文件描述符，SIGIO只通知一遍。所以存在事件丢失的情况，需要采用其他方法弥补。

* /dev/poll
使用虚拟的/dev/poll设备，可以将要监视的文件描述符数组写入这个设备，然后通过ioctl()来等待事件通知，当ioctl()返回就绪的文件描述符后，可以从/dev/poll中读取所有就绪的文件描述符数组，节省了扫描所有文件描述符的开销。

* /dev/epoll
在/dev/poll的基础上增加了内存映射（mmap）的技术

* epoll
Linux2.6中由内核直接支持的实现方法，公认的Linux2.6下性能最好的多路I/O就绪通知方法。
epoll的本质改进在于其基于事件的就绪通知方式，事先通过epoll_ctl()来注册每一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似callback的回调机制迅速激活这个文件描述符，当进程调用epoll_wait()时得到通知，获得就绪的文件描述符的数量的值，然后只需要去epoll指定的数组中依次取得相应数量的文件描述符即可。

* kqueue
性能和epoll接近，但很多平台不支持。


## 直接I/O
在Linux2.6中，内存映射和直接访问文件没有本质上的差异，因为数据从进程用户态内存空间到磁盘都要经过两次复制：磁盘到内核缓冲区、内核缓冲区到用户态内存空间。
对于一些复杂的应用，比如数据库服务器，为了提高性能希望绕过内核缓冲区由自己在用户态空间实现并管理I/O缓冲区以支持独特的查询机制。Linux提供了对这种需求的支持，即在open()系统调用中添加参数O_DIRECT，有效避免CPU和内存的多余时间开销。


## 同步和异步、阻塞和非阻塞概念理解
同步和异步、阻塞和非阻塞修饰的是不同的对象。
阻塞和非阻塞指当进程访问的数据未就绪时，进程是直接返回还是继续等待。
同步和异步指访问数据的机制，同步指主动请求并等待I/O操作完毕，在数据就绪后，读写时必须阻塞。异步指主动请求数据后便可以继续处理其他任务，随后等待I/O操作完毕的通知，使得进程在数据读写时也不发生阻塞。


## rsync
SCP和WebDAV属于主动分发方式的文件复制，Linux的rsync工具属于被动同步的方式，即接收文件的一端主动向服务器发起同步请求，并根据两端文件列表的差异有选择地进行更新。
可以配置crontab脚本定期同步。

## inotify
Linux的inotify模块基于Hash Tree（即一旦某个文件发生更新，就更新从它开始至根目录的整个路径上的所有目录）来监控文件的更改，以此提高文件更新的效率。原生提供C语言的API，PECL有相应的扩展。


## 电子电路对计算机信息的表示
在硬件设计中用电子电路来计算和存储位，大多数现代电路技术都是用信号线上的高低电压来表示不同的值，如逻辑1用1v左右的高电压表示，而逻辑0用0v左右低电压表示。要实现一个数字系统需要三个主要的组成部分：对位进行操作的组合逻辑、存储位的存储器元素、控制存储器元素更新的时钟信号。

硬件控制语言HCL用来描述不同处理器设计的控制逻辑。HCL表达式可以清楚地表明组合逻辑电路和C语言中逻辑表达式（&&、||、!等）的对应之处。
逻辑门是数字电路的基本计算元素，它们产生的输出等于它们输入位值的某个布尔函数。（图略）
很多逻辑门组合成一个网，就能构建计算块，称为组合电路。
通过将逻辑门组合成更大的网，可以构造出能计算更加复杂逻辑的组合电路，比如设计对字进行操作的电路，而不仅仅是对位进行操作。组合逻辑电路可以设计成在字级数据上执行许多不同类型的操作。算术逻辑单元ALU是一种组合电路，这个电路有3个输入：两个数据输入和一个控制输入，根据控制输入的设置，电路会对数字输入执行不同的算术或逻辑操作。组合电路可以实现将一个信号与多个可能匹配信号的比较，以此来检测正在处理的某个指令代码是否属于某一类指令代码。

组合电路不存储任何信息，为了产生时序电路，即有状态且在这个状态上进行计算的系统，必须引入按位存储信息的设备。存储设备都是由同一个时钟控制，时钟周期性发出信号决定什么时候要把新值加载到设备中。

寄存器文件有两个读端口和一个写端口，这样一个多端口随机访问存储器允许同时进行多个读和写操作，比如可以读两个程序寄存器的值，同时更新第三个寄存器的状态。



## Y86处理器顺序执行指令的步骤
* 取指：从存储器读取指令字节，地址为程序计数器PC的值。取出的长度取决于具体指令的字节编码，然后按顺序方式计算当前指令的下一条指令的地址（等于PC的值加上已取出指令的长度）。
* 译码：从寄存器文件读入最多两个操作数，通常读入rA和rB字段指明的寄存器，不过有些指令是读寄存器%esp的。
* 执行：ALU要么执行指令指明的操作（根据ifun值），计算存储器引用的有效地址，要么增加或者减少栈指针。在此，也可能设置条件码。对于跳转指令，这个阶段会验证条件码和（ifun给出的）分支条件，看是不是应该选择分支。
* 访存：将数据写入存储器或者从存储器中读出。
* 写回：最多可以写两个结果到寄存器文件。
* 更新PC：将PC设置为下一条指令的地址。
发生任何异常时，处理器就会停止：执行halt指令或非法指令。

一个时钟变化会引发一个经过组合逻辑的流来执行整个指令。


## 指令集与流水线化处理器
顺序处理器的问题在于太慢了，时钟必须非常慢，以使信号能在一个周期内传播所有的阶段（对应不同的硬件单元）。这种实现方式不能充分利用硬件单元。
流水线化可以增加系统的吞吐量，即单位时间内服务的总用户数。但是对单个用户而言，则会轻微地增加延迟（从头到尾执行一条指令所需要的时间称为延迟）。
相邻指令之间很可能是相关的，可以通过引入含有反馈路径的流水线系统来解决。
CPU能够执行的指令被编码为一个或多个字节序列组成的二进制格式，一个CPU能够执行的所有指令和指令的字节级编码被称为它的指令集体系结构（`ISA` Instruction-Set Architecture）。
ISA模型看上去应该是顺序执行指令，但是现代处理器的实际工作方式并非如此：通过同时处理多条指令的不同部分，处理器可以获得较高的性能（流水线化处理器）。为了保证处理器能达到同顺序执行相同的结果，处理器又采取了一些特殊的机制。


## SRAM、DRAM、RPM、PROM、EPROM、EEPROM
随机访问存储器（Random Access Memory）分为两类：静态的和动态的。静态的（SRAM）比动态的（DRAM)更快，也更贵。SRAM用来做高速缓存，DRAM用来做主存及图形系统的帧缓冲区。

SRAM将每个位存储在一个双稳态的存储器单元里，每个单元是一个六晶体管电路，这个电路有这样一个属性：它可以无限期地保持在两个不同的电压状态之一，其他任何状态都是不稳定的。只要有电，它就会永远地保持它的值。

DRAM将每一位存储为一个电容，与SRAM不同的是，DRAM存储器单元对干扰非常敏感，暴露在光线下也会导致电容电压改变，当电容电压被扰乱后，它就永远不会恢复了。存储器系统必须周期性地通过读出，然后重写来刷新存储器的每一位。

SRAM与DRAM的比较：
```
      每位晶体管数  相对访问时间  是否持续  是否敏感  相对花费
SRAM       6              1          是        否        100    
DRAM       1             10          否        是         1    
```

SRAM和DRAM在断电后都会丢失信息，因此它们都属于易失的。非易失性存储器即使在断电后也仍然能够保存它们的信息，通常指ROM。由于历史原因，虽然ROM中有的类型既可以读也可以写，但是它们整体上都称为只读存储器ROM。

PROM指可以进行一次编程的ROM，PROM的每个存储器单元有一种熔丝，它只能用高电流熔断一次。

EPROM指可擦写可编程ROM，有一个透明的石英窗口，允许光到达存储单元，紫外线照射后，EPROM单元就被清除为0.对其写入1需要使用特殊的设备来完成。EPROM能够被擦除和重编程的次数大概为1000次。

EEPROM指电子可擦除PROM，类似于EPROM，但是它不需要一个物理上独立的编程设备，且可编程次数超过10万次。

闪存基于EEPROM。

固件（firmware）指存储在ROM中的程序，当计算机通电后，会运行存储在ROM中的固件，如BIOS。复杂的设备，如显卡、磁盘控制器也依赖固件翻译来自CPU的I/O请求。

总线是一种共享电子电路，数据流通过总线在处理器和DRAM之间来回传送。如：

磁盘（略）

固态硬盘（Solid State Disk）是一种基于闪存的存储技术。


## 存储器层次结构
```
寄存器 -> L1高速缓存 -> L2高速缓存 -> L3高速缓存 -> 主存 -> 本地磁盘 -> 远程存储
```

## 异常处理与过程调用的区别
异常处理类似于过程调用，但又有一些不同之处：
* 1. 过程调用在跳转到处理程序之前，处理器会将返回地址压入栈中，而异常的返回地址则会根据类型可能是当前指令，也可能是下一条指令。
* 2. 处理器会把处理器状态压到用户栈里以便在处理程序返回时重新开始被中断的程序。如果异常控制从一个用户程序转移到内核，那么所有这些项目都被压到内核栈中，而不是压到用户栈中。
* 3. 异常处理程序运行在内核模式下，因此它们对所有的系统资源都有完全的访问权限。

一旦硬件触发了异常，剩下的工作就由异常处理程序在软件中完成，在处理程序处理完事件之后，它通过执行一条特殊的“从中断返回”指令，可选地返回到被中断的程序，该指令将适当的状态弹回到处理器的控制和数据寄存器中，如果异常中断的是一个用户程序，就将状态恢复为用户模式，然后将控制返回给被中断的程序。


## 地址翻译
当页命中时，CPU硬件的执行步骤如下：
* 1. 处理器生成一个虚拟地址，并把它传送给MMU；
* 2. MMU生成PTE地址，并从高速缓存/主存中请求得到它；
* 3. 高速缓存/主存向MMU返回PTE；
* 4. MMU构造物理地址，并把它传送给高速缓存/主存；
* 5. 高速缓存/主存返回所请求的数据字给处理器；
可见页命中完全是由硬件处理的。

当缺页时，需要硬件和操作系统内核协作完成，步骤如下：
* 1. 处理器生成一个虚拟地址，并把它传送给MMU；
* 2. MMU生成PTE地址，并从高速缓存/主存中请求得到它’
* 3. 高速缓存/主存向MMU返回PTE；
* 4. PTE中的有效位为零，所以MMU触发一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序；
* 5. 缺页处理程序确定出物理存储器中的牺牲页，如果这个页已经被修改了，则把它换出到磁盘；
* 6. 缺页处理程序调入新的页，并更新存储器中的PTE；
* 7. 缺页处理程序返回到原来的进程，再次执行导致缺页的指令，CPU将引起缺页的虚拟地址重新发送给MMU。因为虚拟页面现在缓存在物理存储器中，所以就会被命中，主存会将所请求的字返回给处理器。

在MMU中包括了一个关于PTE的小的缓存，称为TLB（翻译后备缓冲器）。在有TLB，且TLB命中的情况下，CPU的执行步骤如下：
* 1. 处理器生成一个虚拟地址，并把它传送给MMU；
* 2. MMU从TLB中取出相应的PTE；
* 3. MMU构造物理地址，并把它传送给高速缓存/主存；
* 4. 高速缓存/主存返回所请求的数据字给处理器；
























