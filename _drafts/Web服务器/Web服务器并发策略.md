# Web服务器并发策略

从本质上讲所有到达Web服务器的请求都封装在IP包中，位于网卡的接收缓冲区内。Web服务器软件要做的事情就是不断地读取这些请求，进行处理，再将结果写到发送缓冲区。这个过程中涉及很多I/O操作和CPU计算，并发策略的目的就是让I/O操作和CPU计算尽量重叠进行，让CPU在I/O等待时不要空闲，同时在I/O调度上尽量花费最少的时间。

1.一个进程处理一个连接，非阻塞I/O
fork()模式、prefork()模式；
并发连接数有限，但是稳定性和兼容性较好。

2.一个线程处理一个连接，非阻塞I/O
比如Apache的worker模型，这里的线程实际是轻量级进程，实际并不比prefork有太大优势。

3.一个进程处理多个连接，非阻塞I/O
这种模式下，多路I/O就绪通知的性能成为关键。
这种处理多个连接的进程称为work进程，通常数量可配，比如在Nginx中：worker_processes 2;

4.一个线程处理多个连接，异步I/O
对于磁盘文件的操作，设置文件描述符为非阻塞没有任何意义：如果需要读取的数据不在磁盘缓冲区，磁盘便开始动用物理设备来读取数据，这时整个进程的其他工作必须等待。目前几乎没有Web服务器支持基于Linux AIO的工作方式。
