# 局部性原理及编写高速缓存友好的代码

## 局部性
一个编写良好的计算机程序应该具有良好的局部性（locality），即它倾向于引用邻近于其最近引用过的数据项或者最近引用过的数据项本身。局部性有两种形式：时间局部性、空间局部性。

## 存储器层次结构
```
寄存器 -> L1高速缓存 -> L2高速缓存 -> L3高速缓存 -> 主存 -> 本地磁盘 -> 远程存储
```

## 编写高速缓存友好的代码
局部性比较好的程序更容易有较低的不命中率，因而往往运行的更快。应该试着去编写高速缓存友好的代码。包括以下方法：
1.让最常见的情况运行得快：程序通常把大部分时间花在少量核心的函数上，而这些函数通常把大部分时间花在少量的循环上，因此应该把注意力集中在核心函数的循环上，而忽略其他部分。
2.在每个循环内部缓存不命中数量最小：对局部变量的反复引用是好的，因为编译器能够将它们缓存在寄存器文件中。步长为1的引用模式是好的，因为存储器层次结构中所有层次上的缓存都是将数据存储为连续的块。

## 高速缓存对程序性能的影响
存储器系统的性能不是一个数字就能描述的，它是一座时间和空间局部性的`存储器山`（一个变化很大的程序局部性的函数）。

考虑一对n*n的矩阵相乘问题，矩阵乘法通常由三个嵌套循环实现，分别用索引i、j、k表示，改变循环次序可以得到矩阵乘法的6个在功能上等价的版本。从高层来看，这6个版本的功能是一样的，总共都执行O(n^3)个操作，且加法和乘法的数量相同。但是分析最里层循环迭代的行为可以发现在访问数量和局部性上是有区别的。
假设：
C = AB，AB为n*n的数组。只有一个高速缓存，其块大小为32字节，数组n很大，以至于矩阵的一行都不能完全装进L1高速缓存中。
```C
// ijk版本
for(i=0; i<n; i++){
	for(j=0; j<n; j++){
		sum = 0.0;
		for(k=0; k<n; k++){
			sum += A[i][k] * B[k][j];
		}
		C[i][j] += sum;
	}
}

// jki版本
for(j=0; j<n; j++){
	for(k=0; k<n; k++){
		r = B[k][j];
		for(i=0; i<n; i++){
			C[i][j] += A[i][k]*r;
		}
	}
}

// kij版本
for(k=0; k<n; k++){
	for(i=0; i<n; i++){
		r = A[i][k];
		for(j=0; j<n; j++){
			C[i][j] += B[k][j]*r;
		}
	}
}
```
其他版本略，性能测试结果如下：
```
                      ijk&jik   jki&kji   kij&ikj
每次迭代加载次数：       2         2         2
每次迭代存储次数：       0         1         1
每次迭代A不命中次数：   0.25      1.00      0.00
每次迭代B不命中次数：   1.00      0.00      0.25
每次迭代C不命中次数：   0.00      1.00      0.25
每次迭代总不命中次数：  1.25      2.00      0.50
```
对于大的n值，即使每个版本都执行相同数量的浮点数算术操作，最快的版本（不命中次数最小）比最慢的版本运行得几乎快20倍。