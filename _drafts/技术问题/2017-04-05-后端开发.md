---
layout: post
title:  "问题总结：后端开发"
date: 2017-04-05 00:00:05
categories: 技术问题
tags: 后端开发
excerpt: "后端开发相关的面试题，包括Web服务器、网络协议、计算机系统、架构、数据库、缓存等等"
---

* content
{:toc}

# RESTful架构风格理解*

REST并不是一种具体的技术，也不是一种具体的规范，REST其实是一种内涵非常丰富的**架构风格**。它是为运行在互联网环境的分布式超媒体系统量身定制的。**互联网环境与企业内网环境有非常大的差别**，最主要的差别是两个方面：

* （1）可伸缩性需求无法控制：并发访问量可能会暴涨，也可能会暴跌。
* （2）安全性需求无法控制：无法控制客户端发来的请求的格式，很可能会是恶意的请求。

## 分布式应用架构风格

从架构风格的抽象高度来看，**常见的分布式应用架构风格有三种**：

* （1）分布式对象（Distributed Objects，简称`DO`），架构实例有CORBA/RMI/EJB/DCOM/.NET Remoting等等；
* （2）远程过程调用（Remote Procedure Call，简称`RPC`），架构实例有SOAP/XML-RPC/Hessian/Flash AMF/DWR等等；
* （3）表述性状态转移（Representational State Transfer，简称`REST`），架构实例有HTTP/WebDAV；

**REST是HTTP/1.1协议等Web规范的设计指导原则**，HTTP/1.1协议正是为实现REST风格的架构而设计的。REST是所有Web应用都应该遵守的架构设计指导原则。

## REST的五个关键词

* （1）**资源**（Resource）

资源是一种看待服务器的方式，即，**将服务器看作是由很多离散的资源组成**。每个资源是服务器上一个可命名的抽象概念。**一个资源可以由一个或多个URI来标识。URI既是资源的名称，也是资源在Web上的地址**。对某个资源感兴趣的客户端应用，可以通过资源的URI与其进行交互。

* （2）**资源的表述**（Representation）

资源的表述是一段对于**资源在某个特定时刻的状态的描述**。可以在客户端-服务器端之间转移（交换）。资源的表述可以有多种格式，例如HTML/XML/JSON/纯文本/图片/视频/音频等等。资源的表述格式可以通过协商机制来确定。请求-响应方向的表述通常使用不同的格式。

* （3）**状态转移**（State Transfer）

状态转移（state transfer）与状态机中的状态迁移（state transition）的含义是不同的。状态转移说的是：**在客户端和服务器端之间转移代表资源状态的表述**。通过转移和操作资源的表述，来间接实现操作资源的目的。

* （4）**统一接口**（Uniform Interface）

REST要求，必须通过统一的接口来对资源执行各种操作。**对于每个资源只能执行一组有限的操作**。以HTTP/1.1协议为例，定义了一个操作资源的统一接口，主要包括以下内容：  

* 7个HTTP方法：GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS
* HTTP头信息（可自定义）
* HTTP响应状态代码（可自定义）
* 一套标准的内容协商机制
* 一套标准的缓存机制
* 一套标准的客户端身份认证机制

* （5）**超文本驱动**（Hypertext Driven）

`超文本驱动`又名`将超媒体作为应用状态的引擎`（Hypermedia As The Engine Of Application State，来自Fielding博士论文中的一句话，缩写为HATEOAS）。将Web应用看作是一个由很多状态（应用状态）组成的有限状态机。资源之间通过超链接相互关联，**超链接既代表资源之间的关系，也代表可执行的状态迁移**。在超媒体之中不仅仅包含数据，还包含了状态迁移的语义。以超媒体作为引擎，驱动Web应用的状态迁移。通过超媒体暴露出服务器所提供的资源，服务器提供了哪些资源是在运行时通过解析超媒体发现的，而不是事先定义的。从面向服务的角度看，超媒体定义了服务器所提供服务的协议。客户端应该依赖的是超媒体的状态迁移语义，而不应该对于是否存在某个URI或URI的某种特殊构造方式作出假设。一切都有可能变化，只有超媒体的状态迁移语义能够长期保持稳定。

## REST风格的架构所具有的6个主要特征

* （1）面向资源（Resource Oriented）
* （2）可寻址（Addressability）
* （3）连通性（Connectedness）
* （4）无状态（Statelessness）
* （5）统一接口（Uniform Interface）
* （6）超文本驱动（Hypertext Driven）

这6个特征是REST架构设计优秀程度的判断标准。其中，面向资源是REST最明显的特征，即，REST架构设计是以资源抽象为核心展开的。可寻址说的是：每一个资源在Web之上都有自己的地址。连通性说的是：应该尽量避免设计孤立的资源，除了设计资源本身，还需要设计资源之间的关联关系，并且通过超链接将资源关联起来。无状态、统一接口是REST的两种架构约束，超文本驱动是REST的一个关键词。




# TCP粘包理解
TCP是**面向字节**的，即以流式传送，也就是连接建立后可以一直不停的发送，并**没有明确的边界定义**。而UDP是**面向报文**的，发送的时候是可以按照一个一个数据包去发送的，一个数据包就是一个明确的边界。因为TCP是流式传送，所以会开辟一个缓冲区，发送端往其中写入数据，每过一段时间就发送出去，因此有可能后续发送的数据（属于另一个包）和之前发送的数据同时存在缓冲区中并一起发送，造成粘包。接收端也有缓存，因此也存在粘包。
处理粘包的唯一方法就是**制定应用层的数据通讯协议**，通过协议来规范现有接收的数据是否满足消息数据的需要。在应用中处理粘包的基础方法主要有两种分别是**以4节字描述消息大小**或**用结束符**，实际上也有两者相结合的如HTTP，redis的通讯协议等。



# Nagle算法理解

Nagle算法为福特航空和通信公司1984年定义的**TCP拥塞控制方法**。

从键盘输入的一个字符，占用一个字节，可能在传输上造成41字节的包，其中包括1字节的有用信息和40字节的首部数据。这种情况转变成了4000%的消耗，且这些小包同样都需要经过ACK等。这样的情况对于轻负载的网络来说还是可以接受的，但是重负载的网络就受不了了，**会导致网络由于太多的包而过载**。

事实上，Nagle算法所谓的提高网络利用率只是它的一个副作用，**Nagle算法的主旨在于避免发送大量的小包**。Nagle算法并没有阻止发送小包，它只是阻止了发送大量的小包！

**Nagle算法的基本定义是任意时刻，最多只能有一个未被确认的小段**。 所谓`小段`，指的是小于MSS尺寸的数据块，所谓`未被确认`，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。Nagle算法会在TCP程序里添加两行代码，在未确认数据发送的时候让发送器把数据送到缓存里。任何数据随后继续**直到得到明确的数据确认或者直到攒到了一定数量的数据了再发包**。
默认情况下，发送数据采用Nagle算法。这样**虽然提高了网络吞吐量，但是实时性却降低了**，在一些交互性很强的应用程序来说是不允许的，使用`TCP_NODELAY`选项可以禁止Nagle 算法。

# TCP同时打开，同时关闭

## 同时打开

两个应用程序同时执行主动打开。每一端都发送一个SYN，并传递给对方，且每一端都使用对端所知的端口作为本地端口。例如：
主机a中一应用程序使用7777作为本地端口，并连接到主机b 8888端口做主动打开。
主机b中一应用程序使用8888作为本地端口，并连接到主机a 7777端口做主动打开。
**tcp协议在遇到这种情况时，只会打开一条连接**。
这个连接的建立过程需要4次数据交换，而一个典型的连接建立只需要3次交换（即3次握手）
但多数伯克利版的tcp/ip实现并不支持同时打开。
![image](/images/tech/net_10.png)

## 同时关闭

如果应用程序同时发送FIN，则在发送后会首先进入FIN_WAIT_1状态。在收到对端的FIN后，回复一个ACK，会进入CLOSING状态。在收到对端的ACK后，进入TIME_WAIT状态。这种情况称为同时关闭。
同时关闭也需要有4次报文交换，与典型的关闭相同。
![image](/images/tech/net_11.png)



# Referer头的安全问题

## Referer的作用

Referer是HTTP协议中的一个请求报头，用于**告知服务器用户的来源页面**。比如说从Google搜索结果中点击进入了某个页面，那么该次HTTP请求中的Referer就是Google搜索结果页面的地址。如果某篇博客中引用了其他地方的一张图片，那么对该图片的HTTP请求中的Referer就是那篇博客的地址。
一般**Referer主要用于统计**，像CNZZ、百度统计等可以通过Referer统计访问流量的来源和搜索的关键词（包含在URL中）等等，方便站长们有针性对的进行推广和SEO。

Referer另一个用处就是**防盗链**。可以用referrer-killer（一个js库）来实现反反盗链。

Referer是由浏览器自动加上的，**以下情况是不带Referer的**：

* （1）直接输入网址或通过浏览器书签访问
* （2）使用JavaScript的Location.href或者是Location.replace()
* （3）HTTPS等加密协议

## Referer的安全问题

以新浪微博曾经的一个漏洞（新浪微博gsid劫持）为例。
gsid是一些网站移动版的认证方式，移动互联网之前较老的手机浏览器不支持cookie，为了能够识别用户身份（实现类似cookie的作用），就在用户的请求中加入了一个类似sessionid的字符串，通过GET方式传递，带有这个id的请求，就代表用户的帐号发起的操作。后来又因用户多次认证体验不好，gsid的失效期是很长甚至永久有效的（即使改了密码也无用，这个问题在很多成熟的web产品上仍在发生）。也就是说，一旦攻击者获取到了这个gsid，就等同于长期拥有了用户的身份权限。
只要攻击者在微博上给用户发一个链接（指向攻击者的服务器），用户通过手机点击进入之后，手机当前页面的URL就通过Referer主动送到了攻击者的服务器上，攻击者自然就可以轻松拿到用户的gsid进而控制账号。



# Redis通信协议理解
## 发送格式
```
*<参数的个数>CR LF
$<参数1字节数>CR LF
<参数1>CR LF
...
$<参数n字节数>CR LF
<参数n>CR LF
```
例如`set mykey myvalue`命令，相应的字符串为：
```
*3\r\n$3\r\nSET\r\n$5\r\nmykey\r\n$7\r\nmyvalue\r\n
```

## 响应格式
响应的类型都是由返回数据的第一个字节决定的，有如下几种类型：
* "+" 代表一个状态信息，如 +ok 
* "-" 代表发生了错误，如操作运算操作了错误的类型
* ":" 返回的是一个整数，如：":11\r\n。
   一些命令返回一些没有任何意义的整数，如LastSave返回一个时间戳的整数值， INCR返回一个加1后的数值；一些命令如exists将返回0或者1代表是否true or false；其他一些命令如SADD, SREM 在确实执行了操作时返回1 ，否则返回0
* "$" 返回一个块数据，被用来返回一个二进制安全的字符串
* "\*" 返回多个块数据（用来返回多个值， 总是第一个字节为"*"， 后面写着包含多少个相应值，如：
```
C:LRANGE mylist 0 3
S:*4
S:$3
S:foo
S:$3
S:bar
S:$5
$:world
```
如果指定的值不存在，那么返回*0



# Redis的管道技术理解

Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。这意味着通常情况下一个请求会遵循以下步骤：

* （1）客户端向服务端发送一个查询请求，并监听Socket返回，**通常是以阻塞模式**，等待服务端响应。
* （2）服务端处理命令，并将结果返回给客户端。

**Redis管道技术可以在服务端未响应时，客户端能够继续向服务端发送请求，并最终一次性读取所有服务端的响应**。
如：
```
$(echo -en "PING\r\n SET w3ckey redis\r\nGET w3ckey\r\nINCR visitor\r\nINCR visitor\r\nINCR visitor\r\n"; sleep 10) | nc localhost 6379

+PONG
+OK
redis
:1
:2
:3
```
以上实例中通过使用PING命令查看redis服务是否可用，之后设置了w3ckey的值为redis，然后获取w3ckey的值并使得visitor自增3次。在返回的结果中可以看到**这些命令一次性向redis服务提交，并最终一次性读取所有服务端的响应**。管道技术**最显著的优势是提高了redis服务的性能**（批量提交命令）。



# 乐观锁与悲观锁的区别

## 悲观锁

`悲观锁`（Pessimistic Lock）每次去读数据的时候都认为数据会被其他任务修改，所以会上锁，这样其他任务想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁、表锁、读锁、写锁等，都是在做操作之前先上锁。

## 乐观锁

`乐观锁`（Optimistic Lock）每次去读数据的时候都认为别的任务不会修改，所以不会上锁，但是**在更新（写）的时候**会判断一下在此期间其他任务有没有去更新这个数据(可以使用版本号等机制）。**乐观锁适用于多读的应用类型**，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。

两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。



# 僵尸状态是每个子进程必经的状态吗？

是的。 任何一个子进程（init除外）在exit()之后，并非马上就消失掉，而是留下一个称为`僵尸进程`（Zombie）的数据结构，等待父进程处理。**这是每个子进程在结束时都要经过的阶段**。

如果子进程在exit()之后，父进程没有来得及处理，这时用`ps -el`命令就能看到子进程的状态是`Z`。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

# 僵尸进程的危害
由于子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。UNIX提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息，就可以得到。这种机制就是： 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息（包括进程号、退出状态、运行时间等）。直到父进程通过wait/waitpid来取时才释放。但这样就导致了问题，如果进程不调用wait/waitpid的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。此即为僵尸进程的危害，应当避免。


# 分页和分段的主要区别

* **页是信息的物理单位**，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。**段则是信息的逻辑单位**，它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。 
* **页的大小固定且由系统决定**，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而**段的长度却不固定**，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
* **分页的作业地址空间是一维的**，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而**分段的作业地址空间则是二维的**，程序员在标识一个地址时，既需给出段名， 又需给出段内地址。

# 后台进程与守护进程有什么区别？

* 最直观的区别：**守护进程没有控制终端，而后台进程还有**。如通过命令`firefox &`在后台运行firefox，此时firefox虽然在后台运行，但是并没有脱离终端的控制，如果把终端关掉则firefox也会一起关闭。
* 后台进程的文件描述符继承自父进程，例如shell，所以它也可以在当前终端下显示输出数据。但是**守护进程自己变成进程组长**，其文件描述符号和控制终端没有关联，是控制台无关的。
* **守护进程肯定是后台进程，但后台进程不一定是守护进程**。基本上任何一个程序都可以后台运行，但守护进程是具有特殊要求的程序，比如它能够脱离自己的父进程，成为自己的会话组长等（这些需要在程序代码中显式地写出来）。

# 如何查看僵尸进程？

`ps -el`，查看`S`状态：

* `Z`：僵尸进程
* `S`：休眠状态
* `D`：不可中断的休眠状态
* `R`：运行状态
* `T`：停止或跟踪状态



# 僵尸进程变为孤儿进程

父进程死后，僵尸进程成为"孤儿进程"，过继给1号进程init，init会负责清理僵尸进程。



# 如何查看Linux进程之间的关系？
```
ps -o pid,pgid,ppid,comm | cat
```

输出：
```
PID  PGID  PPID COMMAND
3003  3003  2986 su
3004  3004  3003 bash
3423  3423  3004 ps
3424  3423  3004 cat
```

每个进程都会属于一个进程组(process group)，每个进程组中可以包含多个进程。进程组会有一个组长进程 (process group leader)，**组长进程的PID成为进程组的ID** (process group ID, PGID)，以识别进程组。`PID`为进程自身的ID，`PGID`为进程所在的进程组的ID， `PPID`为进程的父进程ID。



# 子进程结束后为什么要进入僵尸状态? 

因为父进程可能要取得子进程的退出状态等信息。 




# 协程理解

## 普通程序调用的执行方式

子程序，或者称为函数，在所有语言中都是**层级调用**，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。
所以**子程序调用是通过栈实现的**，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。

## 协程的执行方式

**协程**
又称微线程，纤程。英文名Coroutine。
协程的调用和子程序不同。
协程看上去也是子程序，但执行过程中，**在子程序内部可中断**，然后转而执行别的子程序（是中断后执行，而不是函数调用其他的子程序），在适当的时候再返回来接着执行。

**优点**
**协程的特点在于是一个线程执行（所以不是多线程）**。优势就是极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，**没有线程切换的开销**，和多线程比，线程数量越多，协程的性能优势就越明显。另一个优势就是**不需要多线程的锁机制**，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

**缺点**
**无法利用多核资源**：协程的本质是个单线程，它不能同时将单个CPU的多个核用上，协程需要和进程配合才能运行在多CPU上。当然我们日常所编写的绝大部分应用都没有这个必要，除非是CPU密集型应用。
**进行阻塞操作会阻塞掉整个程序**：这一点和事件驱动一样，可以使用异步IO操作来解决。



# 死锁产生的四个必要条件

* **互斥条件**：一个资源每次只能被一个进程使用。
* **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
* **不剥夺条件**：进程已获得的资源，在未使用完之前，不能强行剥夺。
* **循环等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系。

这四个条件是死锁的必要条件。只要系统发生死锁，这些条件必然成立，而只要上述条件之
一不满足，就不会发生死锁。



#  Linux用户身份切换

将一般用户变成root：

```
[test@test test]$ su
```

将身份变成username的身份:

```
[root @test /root ]# sudo [-u username] [command]
```

root可以执行test用户的指令，建立test的文件不需要root的密码仍可以执行root的工具，这时就可以使用sudo。由于执行root身份的工作时，输入的密码是用户的密码，而不是root的密码，所以可以减少root密码外泄的可能性。



# Apache与Nginx的I/O模型差异

**Apache处理一个请求是同步阻塞的模式**：每到达一个请求，Apache都会去fork一个子进程去处理这个请求，直到这个请求处理完毕。

**Nginx是基于epoll的异步非阻塞的服务器程序**。




# Linux ext2和ext3文件系统的区别？

## Linux文件系统

Linux ext2/ext3文件系统**使用索引节点来记录文件信息**。索引节点是一个结构，它包含了一个文件的长度、创建及修改时间、权限、所属关系、磁盘中的位置等信息。**一个文件系统维护了一个索引节点的数组，每个文件或目录都与索引节点数组中的唯一一个元素对应**。系统给每个索引节点分配了一个号码，也就是该节点在数组中的索引号，称为**索引节点号**。

Linux文件系统将文件索引节点号和文件名同时保存在目录中。所以，**目录只是将文件的名称和它的索引节点号结合在一起的一张表**，目录中每一对文件名称和索引节点号称为一个`连接`。 **对于一个文件来说有唯一的索引节点号与之对应，对于一个索引节点号，却可以有多个文件名与之对应**。因此，在磁盘上的同一个文件可以通过不同的路径去访问它。
Linux缺省情况下使用的文件系统为ext2，ext2文件系统的确高效稳定。但是，随着Linux系统在关键业务中的应用，Linux文件系统的弱点也渐渐显露出来：其中系统缺省使用的**ext2文件系统是非日志文件系统**。这在关键行业的应用是一个致命的弱点。
ext3文件系统是直接从Ext2文件系统发展而来，目前ext3文件系统已经非常稳定可靠。它完全兼容ext2文件系统。用户可以平滑地过渡到一个日志功能健全的文件系统中来。这实际上了也是ext3日志文件系统初始设计的初衷。

## ext3日志文件系统的特点

* 高可用性

系统使用了ext3文件系统后，即使在非正常关机后，系统也不需要检查文件系统。宕机发生后，恢复ext3文件系统的时间只要数十秒钟。

* 数据的完整性:

ext3文件系统能够极大地提高文件系统的完整性，避免了意外宕机对文件系统的破坏。在保证数据完整性方面，ext3文件系统有2种模式可供选择。其中之一就是**同时保持文件系统及数据的一致性**模式。采用这种方式，你永远不再会看到由于非正常关机而存储在磁盘上的垃圾文件。

* 文件系统的速度

尽管使用ext3文件系统时，有时在存储数据时可能要多次写数据，但是，**从总体上看来，ext3比ext2的性能还要好一些**。这是因为ext3的日志功能对磁盘的驱动器读写头进行了优化。所以，文件系统的读写性能较之ext2文件系统并来说，性能并没有降低。

* 数据转换

由ext2文件系统转换成ext3文件系统非常容易，只要简单地键入两条命令即可完成整个转换过程，用户不用花时间备份、恢复、格式化分区等。用一个ext3文件系统提供的小工具tune2fs，它可以将ext2文件系统轻松转换为ext3日志文件系统。另外，ext3文件系统可以不经任何更改，而直接加载成为ext2文件系统。

* 多种日志模式

ext3有多种日志模式，一种工作模式是对所有的文件数据及metadata（定义文件系统中数据的数据,即数据的数据）进行日志记录（data=journal模式）；另一种工作模式则是只对metadata记录日志，而不对数据进行日志记录，也即所谓data=ordered或者data=writeback模式。系统管理人员可以根据系统的实际工作要求，在系统的工作速度与文件数据的一致性之间作出选择。



# 进程为什么要挂起？

在多进程程序系统中，进程在处理器上交替运行，在运行、就绪和阻塞3种基本状态之间不断地发生变化。由于进程的不断创建，系统资源（特别是主存资源）已不能满足进程运行的要求。此时就必须将某些进程挂起，对换到磁盘镜像区，暂时不参与进程调度，以平衡系统负载的目的。如果系统出现故障，或者是用户调试程序，也可能需要将进程挂起检查问题。
所谓挂起状态，**实际上就是一种静止的状态**。一个进程被挂起后，不管它是否在就绪状态，系统都不分配给它处理机（区别于阻塞状态）。这样**进程的三态模型**（执行、就绪、阻塞）就变为**五态模型**：执行状态、活动就绪状态、静止就绪状态、活动阻塞状态和静止阻塞状态 

* 活动就绪：指进程**在主存并且可被调度**的状态 （对应于三态的就绪状态）
* 静止就绪：指进程**被对换到辅存**时的就绪状态，是不能被直接调度的状态，只有当主存中没有活动就绪态进程，或者是挂起态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活动就绪。 
* 活动阻塞：指进程在主存中。**一旦等待的事件产生，便进入活动就绪状态**（对应于三态的阻塞状态） 
* 静止阻塞：指进程对换到辅存时的阻塞状态。**一旦等待的事件产生，便进入静止就绪状态**。

# 进程通信的类型 

* 共享存储器系统(Shared-Memory System)

  全局变量、共享数据结构、共享存储区

* 消息传递系统(Message passing system)

  进程间的数据交换，是以格式化的消息(message)为单位的；在计算机网络中，又把message称为报文。


* 管道通信(Pipe)

  管道是指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名pipe文件。向管道(共享文件)提供输入的发送进程(即写进程)， 以字符流形式将大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。



# Linux中通过编译安装的方式安装程序，各步骤操作分别做什么工作？

源码要运行，必须先转成二进制的机器码。这是编译器的任务。
对于简单的代码，可以直接调用编译器生成二进制文件后运行，如：

```
$ gcc test.c
$ ./a.out
```
对于复杂的项目，编译过程通常分成3个部分：
```
$ ./configure
$ make  
$ make install
```

整个编译安装过程分为以下步骤：

* 配置

配置信息保存在一个配置文件之中，约定俗成是一个叫做`configure的`脚本文件。通常它是由**autoconf工具**生成的。**编译器通过运行这个脚本，获知编译参数**。如果用户的系统环境比较特别，或者有一些特定的需求，就需要手动向configure脚本提供编译参数，如：

```
# 指定安装后的文件保存在www目录，并且编译时加入mysql模块的支持
$ ./configure --prefix=/www --with-mysql  
```

* 确定标准库和头文件的位置

从配置文件中知道标准库和头文件的位置。

* 确定依赖关系

源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。假定A文件依赖于B文件，编译器应该保证：只有在B文件编译完成后，才开始编译A文件。且当B文件发生变化时，A文件会被重新编译。
**编译顺序保存在一个叫做`makefile`的文件中**，里面列出哪个文件先编译，哪个文件后编译。而**makefile文件由configure脚本运行生成**，这就是为什么编译时configure必须首先运行的原因。

* 预编译头文件

不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，**编译器会在编译源码之前，先编译头文件**。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。不过，并不是头文件的所有内容都会被预编译。用来声明宏的#define命令，就不会被预编译。

* 预处理

编译器就开始替换掉源码中的头文件和宏以及移除注释。

* 编译

编译器就**开始生成机器码**。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。这种转码后的文件称为对象文件（object file）。

* 链接

**把外部函数的代码（通常是后缀名为.lib和.a的文件）添加到可执行文件中**。这就叫做链接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做`静态连接`（static linking）
make命令的作用，就是从第（4）步头文件预编译开始，一直到做完这一步。

* 安装

**将可执行文件保存到用户事先指定的安装目录**。这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为安装（Installation）。

* 操作系统链接

以某种方式**通知操作系统，让其知道可以使用这个程序了**。这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在`/usr/share/applications`目录下的`.desktop`文件中。
make install命令，就用来完成安装和操作系统连接这两步。

* 生成安装包

将上一步生成的可执行文件，做成可以分发的安装包。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。

* 动态链接

开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。



# 静态链接与动态链接比较

静态链接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，兼容性好，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。
动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。
现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。

# 启动Linux守护进程的方法

## Linux进程类型

Linux操作系统包括如下3种不同类型的进程，每种进程都有其自己的特点和属性。

* **交互进程**：由shell启动的进程。可在前台运行，也可在后台运行；


* **批处理进程**：一个进程序列；


* **守护进程**：守护进程是指在后台运行而又没有启动终端或登录shell。守护进程一般由系统开机时通过脚本自动激活启动或者由root用户通过shell启动。守护进程总是活跃的，一般在后台运行，所以它所处的状态是等待处理任务的请求。

## 启动守护进程有如下几种方法

* 在引导系统时启动：通过脚本启动，这些脚本一般位于`/etc/rc.d`中。在/etc目录下的很多rc文件都是启动脚本 。rc0.d、rc1.d、rc2.d、rc3.d、rc4.d、rc5.d、rc6.d，其中的数字代表在指定的runlevel下运行相应的描述，0代表关机，6代表重启。其中，以k开头的文件表示关闭，以s开头的文件表示重启。可查看相应文件夹中的readme文件。rc0.d、rc1.d、rc2.d、rc3.d、rc4.d、rc5.d、rc6.d、rcS.d都连接到`/etc/init.d`文件夹，**该目录中存放着守护进程的运行文件**。
* 人工手动从shell提示符启动：**任何具有权限的用户都可以启动相应的守护进程**。
```
# 启动FTP服务器，ubuntu下默认已经安装了vsfptd服务器
root@Ubuntu:~# /etc/init.d/vsftpd start
```
* 使用crond守护进程启动
* 执行at命令启动

# nohup与&的区别

最直观的区别：

使用&执行的命令，要是关闭终端（将发出SIGHUP信号），命令会停止。而使用nohup执行的命令，既使把终端关了，命令仍然会继续运行。

nohup执行的命令会**忽略所有挂断（SIGHUP）信号**。

一般结合使用：nohup command & 

# select、poll、epoll

## 文件描述符（fd）

**文件描述符是一个简单的整数**，用以标明每一个**被进程所打开的文件和socket的索引**。第一个打开的文件是0，第二个是1，依此类推。最前面的三个文件描述符（0、1、2）分别与标准输入（stdin），标准输出（stdout）和标准错误（stderr）对应。**Unix操作系统通常给每个进程能打开的文件数量强加一个限制**。当用完所有的文件描述符后，将不能接收用户新的连接，直到一部分当前请求完成，相应的文件和socket被关闭。

## IO多路复用技术

select，poll，epoll都是IO多路复用的机制。I/O多路复用通过一种机制，可以**监视多个文件描述符**，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**select、poll、epoll本质上都是同步I/O，因为它们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间**。

## epoll的改进

* **select、poll需要自己不断轮询所有fd集合**，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是**select和poll在醒着的时候要遍历整个fd集合，而epoll在醒着的时候只要判断一下就绪链表是否为空就行了**，这节省了大量的CPU时间。这就是**回调机制带来的性能提升**（本质的改进在于epoll采用基于事件的就绪通知方式）。
* select、poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。（本质的改进就是使用了**内存映射**（mmap）技术）

epoll被公认为Linux2.6下性能最好的多路I/O就绪通知方法，**实现高效处理百万句柄**。


# MySQL语句的执行顺序
MySQL的语句执行一共分为11步，最先执行的总是FROM操作，最后执行的是LIMIT操作。其中**每一个操作都会产生一张虚拟的表**，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是**只有最后一个虚拟的表才会被作为结果返回**。如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。

* `FORM`：对FROM的左边的表和右边的表计算笛卡尔积，产生虚表VT1。

* `ON`：对虚表VT1进行ON筛选，只有那些符合<join-condition>的行才会被记录在虚表VT2中。

* `JOIN`：如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3, 如果from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。

* `WHERE`：对虚拟表VT3进行WHERE条件过滤。只有符合<where-condition>的记录才会被插入到虚拟表VT4中。

* `GROUP BY`：根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5。

* `CUBE|ROLLUP`：对表VT5进行cube或者rollup操作，产生表VT6。

* `HAVING`：对虚拟表VT6应用having过滤，只有符合<having-condition>的记录才会被 插入到虚拟表VT7中。

* `SELECT`：执行select操作，选择指定的列，插入到虚拟表VT8中。

* `DISTINCT`：对VT8中的记录进行去重。产生虚拟表VT9。

* `ORDER BY`：将虚拟表VT9中的记录按照<order_by_list>进行排序操作，产生虚拟表VT10。

* `LIMIT`：取出指定行的记录，产生虚拟表VT11, 并将结果返回。

# SQL_CALC_FOUND_ROWS

在很多分页的程序中都这样写:

```
SELECT COUNT(*) from 'table' WHERE ......;      # 查出符合条件的记录总数
SELECT * FROM 'table' WHERE ...... LIMIT M,N;   # 查询当页要显示的数据
```
这样的语句可以改成:
```
SELECT SQL_CALC_FOUND_ROWS * FROM 'table' WHERE ......  LIMIT M, N;
SELECT FOUND_ROWS();
```
这样**只要执行一次较耗时的复杂查询**可以同时得到**与不带LIMIT同样的记录条数**：第二个SELECT返回一个数字，指示了在没有LIMIT子句的情况下，第一个SELECT返回了多少行。

# 两大类触发器

## DML触发器

是**基于表而创建的**，可以在一张表创建多个DML触发器。其特点是定义在表或者视图上、**自动触发、不能被直接调用**。用户可以针对INSERT、UPDATE、DELETE语句分别设置触发器，也可以针对一张表上的特定操作设置。触发器可以容纳非常复杂的SQL语句，但不管操作多么复杂，也只能作为一个独立的单元被执行、看作一个事务。如果在执行触发器的过程中发生了错误，则整个事务都会回滚。

## DDL触发器

是一种特殊的触发器，它在响应数据定义语言(DDL)语句时触发。可以用于在数据库中执行管理任务，例如审核以及规范数据库操作。

# 主键与唯一索引的区别

* UNIQUE KEY可空，PRIMARY KEY 不可空不可重复；

* UNIQUE KEY可以在一个表里的一个或多个字段定义（多个UNIQUE KEY可以同时存在），在一个表中只能有一个PRIMARY KEY；

* PRIMARY KEY一般在逻辑设计中**用作记录标识**，这也是设置PRIMARY KEY的本来用意，而UNIQUE KEY只是为了保证域/域组的唯一性。

  ​

# InnDB行级锁理解

如果是InnoDB引擎，就可以在事务里使用行锁，比如使用FOR UPDATE：

```
SELECT xx FROM xx [FORCE INDEX(PRIMARY)] WHERE xx FOR UPDATE 
```
被加锁的行，其他事务也能读取但如果想写的话就必须等待锁的释放（**乐观锁**）。

InnoDB的行锁是针对索引加的锁，不是针对记录加的锁，**只有查询能够使用索引时才可以使用行级锁**。不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。



# 冷备份和热备份比较

## 冷备份

发生在**数据库已经正常关闭**的情况下，当正常关闭时会提供给我们一个完整的数据库。**冷备份是将关键性文件拷贝到另外位置的一种说法**。对于备份数据库信息而言，冷备份是最快和最安全的方法。

**优点：** 

* 是非常快速的备份方法（只需拷贝文件） 
* 容易归档（简单拷贝即可） 
* 容易恢复到某个时间点上（只需将文件再拷贝回去） 
* 能与归档方法相结合，做数据库最新状态的恢复。 
* 低度维护，高度安全。 

**缺点： **

* 单独使用时，只能提供到某一时间点上的恢复
* 在实施备份的全过程中，数据库必须要作备份而不能作其它工作。也就是说，在冷备份过程中，数据库必须是关闭状态 
* 若磁盘空间有限，只能拷贝到磁带等其它外部存储设备上，速度会很慢
* 不能按表或按用户恢复

值得注意的是冷备份必须在数据库关闭的情况下进行，当数据库处于打开状态时，执行数据库文件系统备份是无效的 。而且在恢复后一定要把数据库文件的属组和属主改为mysql。

## 热备份

**在数据库运行的情况下**，备份数据库操作的SQL语句，当数据库发生问题时，可以重新执行一遍备份的SQL语句。

**优点：**

* 可在表空间或数据文件级备份，备份时间短。 
* 备份时数据库仍可使用。 
* 可达到秒级恢复（恢复到某一时间点上）。 
* 可对几乎所有数据库实体作恢复。 
* 恢复是快速的，在大多数情况下在数据库仍工作时恢复。 

**缺点：**

* 不能出错，否则后果严重。 
* 若热备份不成功，所得结果不可用于时间点的恢复。 
* 因难于维护，所以要特别仔细小心，不允许以失败而告终。

MySQL原生支持多机热备。



# 数据库连接池理解

由于**创建连接和释放连接都有很大的开销**（尤其是数据库服务器不在本地时，每次建立连接都需要进行TCP的三次握手，再加上网络延迟，造成的开销是不可忽视的），为了提升系统访问数据库的性能，可以**事先创建若干连接置于连接池中，需要时直接从连接池获取，使用结束时归还连接池而不必关闭连接，从而避免频繁创建和释放连接所造成的开销**，这是典型的用**空间换取时间**的策略。

**连接池仅在超大型应用中才有价值**。普通的应用采用MySQL长连接方案，每个php-fpm创建一个MySQL连接，每台机器开启100个php-fpm进程。如果有10台机器，每台机器并发的请求为100。实际上只需要创建1000个MySQL连接就能满足需求，数据库的压力并不大。即使有100台机器，硬件配置好的存储服务器依然可以承受。
达到数百或者数千台应用服务器时，MySQL服务器就需要维持十万级的连接。这时数据库的压力就会非常大了。连接池技术就可以派上用场了，可以大大降低数据库连接数。
基于swoole的AsyncTask模块实现的连接池是完美方案，编程简单，没有数据同步和锁的问题。甚至可以多个服务共享连接池。缺点是灵活性不如多线程连接池，无法动态增减连接，且有一次进程间通信的开销。
node.js/ngx_lua等在多进程的模式下，无法开发出真正的连接池，除非也像swoole_task这样来实现。



# 外联接

LEFT OUTER JOIN或LEFT JOIN \ RIGHT OUTER JOIN或RIGHT JOIN \ FULL OUTER JOIN或FULL JOIN。

左外联接的结果集中除了包括满足条件的行外，还包括**左表所有的行**，左表中没有满足条件的以空值的形式出现。



# 为SELECT语句添加一个自动增加的列

```
set @N = 0;
SELECT @N := @N +1 AS number, name, surname FROM gbtags_users;
```



# 分析MySQL语句执行时间和消耗资源

```
SET profiling=1;               # 启动profiles，默认是没开启的
SELECT * FROM customers;       # 执行要分析的SQL语句

SHOW profiles;                 # 查看SQL语句具体执行步骤及耗时
SHOW profile cpu,block io FOR QUERY 41;   # 查看ID为41的查询在各个环节的耗时和资源消耗
```



# 使用EXPLAIN分析MySQL语句的执行情况

```
mysql> explain select * from t_online_group_records where UNIX_TIMESTAMP(gre_updatetime) > 123456789;
+----+-------------+------------------------+------+---------------+------+---------+------+------+-------------+
| id | select_type | table                  | type | possible_keys | key  | key_len | ref  | rows | Extra      |
+----+-------------+------------------------+------+---------------+------+---------+------+------+-------------+
|  1 | SIMPLE      | t_online_group_records | ALL  | NULL          | NULL | NULL    | NULL |   47 | Using where |
+----+-------------+------------------------+------+---------------+------+---------+------+------+-------------+
1 row in set (0.00 sec)
```
重点关注type，rows和Extra。

## type
操作的类型，可以用来**判断有无使用到索引**。结果值从好到坏：
```
... > RANGE(使用到索引) > INDEX > ALL(全表扫描)
```
**一般查询应达到range级别**，具体可能值如下：
* SYSTEM ：CONST的特例，当表上只有一条记录时
* CONST ：WHERE条件筛选后表上至多有一条记录匹配时，比如`WHERE ID = 2`
* EQ_REF ：参与连接运算的表是内表（两表连接时作为循环中的内循环遍历的对象，这样的表称为内表）。基于索引（连接字段上存在唯一索引或者主键索引，且操作符必须是“=”谓词，索引值不能为NULL）做扫描，使得**对外表的一条元组，内表只有唯一一条元组与之对应**。
* REF ：可以用于单表扫描或者连接。参与连接运算的表，是内表。
  基于索引（连接字段上的索引是非唯一索引，操作符必须是“=”谓词，连接字段值不可为NULL）做扫描，使得对外表的一条元组，内表可有若干条元组与之对应。
* REF_OR_NULL ：类似REF，只是搜索条件包括：连接字段的值可以为NULL的情况，比如 where col = 2 or col is null
* RANGE ：**范围扫描**，基于索引做范围扫描，为诸如BETWEEN、IN、>=、LIKE类操作提供支持
* INDEX_SCAN ：索引做扫描，是基于索引在索引的叶子节点上找满足条件的数据（不需要访问数据文件）
* ALL ：`全表扫描`或者范围扫描：不使用索引，顺序扫描，直接读取表上的数据（访问数据文件）
* UNIQUE_SUBQUERY ：在子查询中，基于唯一索引进行扫描，类似于EQ_REF
* INDEX_SUBQUERY ：在子查询中，基于除唯一索引之外的索引进行扫描
* INDEX_MERGE ：多重范围扫描。两表连接的每个表的连接字段上均有索引存在且索引有序，结果合并在一起。适用于作集合的并、交操作。
* FT ：FULL TEXT，`全文检索`

## rows
SQL执行检查的记录数

## Extra
SQL执行的附加信息，如**Using index表示查询只用到索引列**，不需要去读表等。



# CASE…WHEN…THEN

使用CASE来重新定义数值类型

```
SELECT id,title,(CASE date WHEN '0000-00-00' THEN '' ELSE date END) AS date
FROM your_table
  
SELECT id,title,
(CASE status WHEN 0 THEN 'open' WHEN 1 THEN 'close' ELSE 'standby' END) AS status
FROM your_table
```



# 通俗地理解三个范式

* 第一范式：是**对属性的原子性约束**，要求属性具有原子性，不可再分解； 
* 第二范式：是**对记录的惟一性约束**，要求记录有惟一标识，即实体的惟一性； 
* 第三范式：是**对字段冗余性的约束**，即任何字段不能由其他字段派生出来，它要求字段没有冗余（没有冗余的数据库未必是最好的数据库）。 



# MySQL基本备份与恢复操作

## 导出数据
```
# mysqldump -u 用户名 -p 数据库名 [表名] > 导出的文件名
mysqldump -uroot -p test mytable > mytable.20140921.bak.sql
```

## 导出备份数据之后发送的写操作
**先使用mysqlbinlog导出这部分写操作SQL**(基于时间点或位置)
```
# 导出2014-09-21 09:59:59之后的binlog
mysqlbinlog --database="test" --start-date="2014-09-21 09:59:59" /var/lib/mysql/mybinlog.000001 > binlog.data.sql

# 导出起始id为123456之后的binlog：
mysqlbinlog --database="test" --start-position="123456" /var/lib/mysql/mybinlog.000001 > binlog.data.sql
```

## 导入备份数据
```
mysql -uroot -p test < mytable.20140921.bak.sql
```

## 导入binlog
```
mysql -uroot -p test < binlog.data.sql
```



# 存储过程的概念以及优缺点理解

存储过程是一套已经预先编译好的SQL代码，是SQL语句和可选控制语句的集合及一个独立的数据库对象。存储过程在数据库内可以由应用程序调用执行，而且允许用户声明变量、有条件执行以及其他强大的编程功能。由于存储过程是已经编译好的代码，所以执行的时候不需要分析也不需要再次编译，能够提高程序的运行效率。
存储过程可以包含程序流、逻辑以及对数据库的查询。可以接受参数、输出参数、返回单个或者多个结果集以及返回值。

## 带简单参数的存储过程

```sql
/*带学号参数的存储过程*/
CREATE PROCEDURE s
@id int/*参数*/
AS
SELECT * FROM student
WHERE id=@id
GO
```
```
/*输入参数2001002的学生号，查询学号2001002学生的信息*/
s 2001002
GO
```
**优点**

* 存储过程可以用于**降低网络流量**，存储过程代码直接存储于数据库中，所以不会产生大量T-sql语句的代码流量。
* 通过向用户授予对存储过程（而不是基于表）的访问权限，它们可以提供对特定数据的访问

**缺点** 

* 如果更改范围大到需要对输入存储过程的参数进行更改，或者要更改由其返回的数据，则仍需要更新程序集中的代码以添加参数、更新 GetValue() 调用，等等，比较繁琐。 

* 可移植性差：由于存储过程将应用程序绑定到 SQL Server，因此使用存储过程封装业务逻辑将限制应用程序的可移植性。

* 很多存储过程不支持面向对象的设计，无法采用面向对象的方式将业务逻辑进行封装，从而无法形成通用的可支持复用的业务逻辑框架。

   ​

# ON DUPLICATE KEY UPDATE

```
# VALUES用来取插入的值，存在主键冲突时就更新，没有删除操作
INSERT INTO ... ON DUPLICATE KEY UPDATE col=VALUES(col)   
```

例：更新统计表
```
select * from player_count where player_id = 1;               # 查询统计表中是否有记录
insert into player_count(player_id,count) value(1,1);         # 没有记录就执行insert 操作
update player_count set count = count+1 where player_id = 1;  # 有记录就执行update操作
```
用ON DUPLICATE KEY UPDATE的做法如下：
```
insert into player_count(player_id,count) value(1,1) on duplicate key update count=count+1;
```



# 慢查询日志分析

## 慢查询日志格式

```
User@Host: edu_online[edu_online] @  [10.139.10.167]
Query_time: 1.958000  Lock_time: 0.000021 Rows_sent: 254786  Rows_examined: 254786
SET timestamp=1410883292;
select * from t_online_group_records;
```
日志显示该查询用了1.958秒，返回254786行记录，一共遍历了254786行记录。及具体的时间戳和SQL语句。

## 使用mysqldumpslow进行慢查询日志分析

输入：
```
mysqldumpslow -s t -t 5 slow_log_20140819.txt 
```
-s：排序方法，t表示按时间（此外，c为按次数，r为按返回记录数等）
-t：取Top多少条，-t 5表示取前5条

输出：
```
Count: 1076100  Time=0.09s (99065s)  Lock=0.00s (76s)  Rows=408.9 (440058825), edu_online[edu_online]@28hosts
  select * from t_online_group_records where UNIX_TIMESTAMP(gre_updatetime) > N
Count: 1076099  Time=0.05s (52340s)  Lock=0.00s (91s)  Rows=62.6 (67324907), edu_online[edu_online]@28hosts
  select * from t_online_course where UNIX_TIMESTAMP(c_updatetime) > N
Count: 63889  Time=0.78s (49607s)  Lock=0.00s (3s)  Rows=0.0 (18), edu_online[edu_online]@[10.213.170.137]
  select f_uin from t_online_student_contact where f_modify_time > N
...
```
以第1条为例，表示这类SQL（N可以取很多值，这里mysqldumpslow会归并起来）在8月19号的慢查询日志内出现了1076100次，总耗时99065秒，总返回440058825行记录，有28个客户端IP用到。
通过慢查询日志分析，就可以找到最耗时的SQL，然后进行具体的SQL分析了

## 慢查询相关的配置参数
```
log_slow_queries               # 是否打开慢查询日志，得先确保=ON后面才有得分析
long_query_time                # 查询时间大于多少秒的SQL被当做是慢查询，一般设为1S
log_queries_not_using_indexes  # 是否将没有使用索引的记录写入慢查询日志
slow_query_log_file            # 慢查询日志存放路径
```

# MySQL性能优化技巧小结

* 优化MySQL查询语句，使其使用查询缓存

对于相同的查询MySQL引擎会使用缓存，但是如果在SQL语句中使用函数，如NOW()、RAND()、 CURDATE()等等，则拼凑出的查询不会被认为是相同的查询。
```php
// 查询缓存不开启
$r = mysql_query("SELECT username FROM user WHERE signup_date >= CURDATE()");

// 开启查询缓存
$today = date("Y-m-d");
$r = mysql_query("SELECT username FROM user WHERE signup_date >= $today");
```

* 当只要一行数据时使用LIMIT 1
  这样MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。

* 为搜索字段建索引
  索引并不一定就是给主键或是唯一的字段。如果在表中有某个字段总要会经常用来做搜索，那么就为其建立索引。

* **在JOIN表的时候使用相同类型的列，并将其索引**
  对于那些STRING类型，还需要有相同的字符集才行（两个表的字符集有可能不一样）

* 千万不要ORDER BY RAND()
  You cannot use a column with RAND() values in an ORDER BY clause, because ORDER BY 
  would evaluate the column multiple times. 
  当记录数据过多时，会非常慢。

* 避免SELECT *

* 使用ENUM而不是VARCHAR
  ENUM实际保存的是TINYINT，但其外表上显示为字符串。如果有一个字段的取值是有限而且固定的，那么，应该使用ENUM而不是VARCHAR。

* **尽可能的使用NOT NULL**
  “NULL columns require additional space in the row to record whether their values are NULL. For MyISAM tables, each NULL column takes one bit extra, rounded up to the nearest byte.”
  NULL值需要额外的存储空间，而且在比较时也需要额外的逻辑。

* 把IP地址存成UNSIGNED INT，而不是VARCHAR(15)

* **固定长度的表会更快**
  如果表中的所有字段都是固定长度的，整个表会被认为是`static`或`fixed-length`。

* 垂直分割
  垂直分割是一种把数据库中的大表按列变成几张小表的方法，这样可以降低表的规模、方便使用缓存。
  需要注意的是，这些被分出去的字段所形成的表，不应该会被经常性地去JOIN，否则性能会比不分割时还要差很多。

* 拆分大的DELETE或INSERT语句
  因为这两个操作是会锁表的。如果有一个大的处理，一定把其拆分，使用LIMIT条件是一个好的方法。下面是一个示例：
```php
while (1) {

  // 每次只做1000条
  mysql_query("DELETE FROM logs WHERE log_date <= '2009-11-01' LIMIT 1000");
  if (mysql_affected_rows() == 0) {
    // 没得可删了，退出！
    break;
  }

  // 每次都要休息一会儿
  usleep(50000);
}
```

* 越小的列会越快
  如使用TINYINT而不是INT，使用DATE而不是DATETIME。

* 选择一个正确的存储引擎
  MyISAM对于SELECT COUNT(*)这类的计算非常快，但是不支持行锁（写操作会锁表），也不支持事务。
  InnoDB的趋势会是一个非常复杂的存储引擎，对于一些小的应用，它会比MyISAM还慢。

* 持久链接
  持久链接的目的是用来减少重新创建MySQL链接的次数。当一个链接被创建了，它会永远处在连接的状态，就算是数据库操作已经结束了。自从Apache开始重用它的子进程后下一次的HTTP请求会重用Apache的子进程，并重用相同的MySQL链接。

* 尽量早做过滤，使JOIN或者UNION等后续操作的数据量尽量小。

* 把能在逻辑层算的提到逻辑层来处理，如一些数据排序、时间函数计算等。


# 查看MySQL编码设置
```
SHOW VARIABLES LIKE 'character_set_%';

Variable_name             Value                             
------------------------  ----------------------------------
character_set_client      utf8mb4                           
character_set_connection  utf8mb4                           
character_set_database    utf8mb4                           
character_set_filesystem  binary                            
character_set_results     utf8mb4                           
character_set_server      utf8mb4                           
character_set_system      utf8                              
character_sets_dir        /usr/local/mysql/share/charsets/  
```

# MySQL覆盖索引理解
对于
```
SELECT a FROM … WHERE b = …
```
这种查询，通常的做法是在b字段上建立索引，执行查询时系统会查询b索引进行定位，然后再利用此定位去表里查询需要的数据a。即该过程存在两次查询，一次是查询索引，一次是查询表。
使用Covering Index可以只查询一次索引就完成。建立一个组合索引`b,a`，当查询时，通过组合索引的b部分去定位，至于需要的数据a，立刻就可以在索引里得到，从而**省略了表查询的过程**。
如果使用Covering Index，要**注意SELECT的方式，只SELECT必要的字段**，而不能SELECT *，因为不太可能把所有的字段一起做索引。

可以使用EXPLAIN命令来确认是否使用了组合索引：**如果在Extra里出现`Using Index`，就说明使用的是Covering Index**。

**实例1：**
```
SELECT COUNT(*) FROM articles WHERE category_id = …
```
当在category_id建立索引后，这个查询使用的就是Covering Index（即，只查索引，而没有查表）。

**实例2：**
比如说在文章系统里分页显示的时候，一般的查询是这样的：
```
SELECT id, title, content FROM article ORDER BY created DESC LIMIT 10000, 10;
```
通常这样的查询会把索引建在created字段（其中id是主键），不过当LIMIT偏移很大时，查询效率仍然很低，改变一下查询：
```
SELECT id, title, content FROM article
INNER JOIN (
  SELECT id FROM article ORDER BY created DESC LIMIT 10000, 10
) AS page USING(id)
```
此时，建立复合索引`created, id`就可以在子查询里利用上Covering Index，快速定位id。



# 视图理解

也被称为**虚拟的表**，其内容由SELECT查询语句定义。同真实的表一样，视图包含了一系列带有名称的列和行的数据。但是，**视图并不在数据库中以存储的数据集合形式存在**。用行和列的数据，来自由定义视图的查询所引用的表，并且在引用视图时动态生成。

视图一经定义，便存储在数据库中，**与其相对应的数据并没有像表那样又在数据库中再存储一份**。通过视图看到的数据只是存放在基表中的数据。对视图的操作与对表的操作一样，可以查询、修改、删除。**通过对视图看到的数据进行修改时，相应的基表的数据也要发生变化，同时，若基表的数据发生变化，这种变化也可以自动地反映到视图中**。
视图和查询最主要的差别是：视图的存储是作为数据库开发者设计数据库的一部分；而查询仅仅是对表的查询并非数据库设计的一部分。



# B树理解

B树是对二叉查找树的改进。它的设计思想是，将相关数据尽量集中在一起，以便一次读取多个数据，减少硬盘操作次数。
**特点如下：**

* 一个节点可以容纳多个值
* 除非数据已经填满，否则不会增加新的层。也就是说，**B树追求"层"越少越好**。
* 子节点中的值，与父节点中的值，有严格的大小对应关系。一般来说，如果父节点有a个值，那么就有a+1个子节点。

这种数据结构，非常有利于减少读取硬盘的次数。**假定一个节点可以容纳100个值，那么3层的B树可以容纳100万个数据，如果换成二叉查找树，则需要20层**。假定操作系统一次读取一个节点，并且根节点保留在内存中，那么B树在100万个数据中查找目标值，只需要读取两次硬盘。
数据库以B树格式储存，只解决了按照"主键"查找数据的问题。如果想查找其他字段，就需要建立索引（index）。所谓索引，就是以某个字段为关键字的B树文件（这里仅指基于B树的索引）。



# MySQL GROUP BY注意点

* 在SELECT指定的字段要么就要包含在GROUP BY语句的后面，作为分组的依据；要么就要被包含在聚合函数中

* HAVING子句的作用是筛选满足条件的组，即**在分组之后过滤数据**

  ​


# innodb_buffer_pool_size

innodb_buffer_pool_size这个参数主要作用是设置缓存innodb表的索引、数据、插入数据时的缓冲的缓存区大小。
默认值：128M，操作系统内存的70%-80%最佳。
此外，这个参数是非动态的，要修改这个值，**需要重启mysqld服务**。

如果因为内存不够，MySQL无法启动，就会在错误日志中出现如下报错：

```
InnoDB: mmap(137363456 bytes) failed; errno 12
```



# LIMIT语句理解

返回不多于5行（小于等于）

```
SELECT prod_name
FROM products
LIMIT 5;
```

返回从第6行开始的5行（行号从0开始）
```
SELECT prod_name
FROM products
LIMIT 5,5;
```

返回从第6行开始的5行（LIMIT的一种替代语法）
```
SELECT prod_name
FROM products
LIMIT 5 OFFSET 5;
```



# MyISAM和InnoDB的比较

* MySQL默认采用的是MyISAM。

* **MyISAM不支持事务**，而InnoDB支持。**InnoDB的AUTOCOMMIT默认是打开的**，即每条SQL语句会默认被封装成一个事务，自动提交，这样会影响速度，所以最好是把多条SQL语句显示放在begin和commit之间，组成一个事务去提交。

* InnoDB支持数据行级锁，**MyISAM不支持行锁定**，只支持锁定整个表。即MyISAM同一个表上的读锁和写锁是互斥的，MyISAM并发读写时如果等待队列中既有读请求又有写请求，默认写请求的优先级高，即使读请求先到，所以MyISAM不适合于有大量查询和修改并存的情况，那样查询进程会长时间阻塞。

* InnoDB支持外键，**MyISAM不支持外键**。

* **InnoDB的主键范围更大**，最大是MyISAM的2倍。

* **InnoDB不支持全文索引**，而MyISAM支持。全文索引是指对char、varchar和text中的每个词（停用词除外）建立倒排序索引。MyISAM的全文索引其实作用不大，因为它不支持中文分词，必须由使用者分词后加入空格再写到数据表里，而且少于4个汉字的词会和停用词一样被忽略掉。

* **MyISAM支持GIS数据**，InnoDB不支持。即MyISAM支持以下空间数据对象：Point、Line、Polygon、Surface等。

* **没有where的count(*)使用MyISAM要比InnoDB快得多**。因为MyISAM内置了一个计数器，`count(*)`时它直接从计数器中读，而InnoDB必须扫描全表。所以在InnoDB上执行`count(*)`时一般要伴随where，且where中要包含**主键以外的**索引列（因为InnoDB中PRIMARY KEY是和raw data存放在一起的，而其他index则是单独存放，然后有个指针指向PRIMARY KEY。所以只是`count(*)`的话使用其他index扫描更快，而PRIMARY KEY则主要在扫描索引同时要返回raw data时的作用较大）。

  ​

# MySQL一行记录最多能有多少个VARCHAR(255)类型的列？

**MySQL表中一行的长度不能超过65535字节**，VARCHAR(N)使用额外的1到2字节来存储值的长度，如果N<=255，则使用一个字节，否则使用两个字节；如果表格的编码为UTF8（一个字符占3个字节），那么VARCHAR(255)占用的字节数为255 * 3 + 2 = 767，这样，一行就最多只能有65535 / 765 = 85个VARCHAR(255)类型的列。



# MySQL事务隔离级别（ISOLATION LEVEL）理解

## READ UNCOMMITTED
最低的隔离级别，可读取其他事务未提交的数据（事务可以看到其他事务尚未提交的修改），可能造成脏读。

## READ COMMITTED
只能读取已提交的数据，但是不可重复读（避免脏读）

## REPEATABLE READ
可重复读。
用户A查询完之后，用户B将无法更新用户A所查询到的数据集中的任何数据（但是可以更新、插入和删除用户A查询到的数据集之外的数据），直到用户A事务结束才可以进行更新，这样就有效的**防止用户在同一个事务中读取到不一致的数据**。

## SERIALIZABLE
事务串行化，必须等待当前事务执行完，其他事务才可以执行写操作，有多个事务同时设置SERIALIZABLE时会产生死锁：
```
ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
```
这是四个隔离级别中限制最大的级别。因为并发级别较低，所以应只在必要时才使用该选项。

## 使用事务时设置隔离级别
```
START TRANSACTION
SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE}
COMMIT
ROLLBACK
```



# MySQL分区表理解

分区是一种粗粒度，简易的索引策略，适用于大数据的过滤场景。**对于大数据（如10TB）而言，索引起到的作用相对小**，因为索引的空间与维护成本很高，另外如果不是索引覆盖查询，将导致回表，造成大量磁盘IO。
分区表分为RANGE、LIST、HASH、KEY四种类型，并且**分区表的索引是可以局部针对分区表建立的**。
用RANGE创建分区表：

```
CREATE TABLE sales (
  id INT AUTO_INCREMENT,
  amount DOUBLE NOT NULL,
  order_day DATETIME NOT NULL,
  PRIMARY KEY(id, order_day)
) ENGINE=Innodb PARTITION BY RANGE(YEAR(order_day)) (
  PARTITION p_2010 VALUES LESS THAN (2010),
  PARTITION p_2011 VALUES LESS THAN (2011),
  PARTITION p_2012 VALUES LESS THAN (2012),
  PARTITION p_catchall VALUES LESS THAN MAXVALUE);
```
如果这么做，则order_day必须包含在主键中，且会产生一个问题：当年份超过阈值，到了2013，2014时需要手动创建这些分区，更好的方法是使用HASH：
```
CREATE TABLE sales ( 
  id INT PRIMARY KEY AUTO_INCREMENT,
  amount DOUBLE NOT NULL,
  order_day DATETIME NOT NULL
) ENGINE=Innodb PARTITION BY HASH(id DIV 1000000);
```
这种分区表示每100W条数据建立一个分区，且没有阈值范围的影响。

如果想为一个表创建分区，这个表最多只能有一个唯一索引（主键也是唯一索引）。如果没有唯一索引，可指定任何一列为分区列；否则就只能指定唯一索引中的任何一列为分区列。查询时需用到分区的列，不然会遍历所有的分区，比不分区的查询效率还低，MySQL支持子分区。
在表建立后也可以新增、删除、合并分区。



# MySQL主从同步理解

## 复制机制（Replication）

master通过复制机制，将master的写操作通过`binlog`传到slave生成中继日志(`relaylog`)，slave再将中继日志redo，使得主库和从库的数据保持同步。

## slave主动拉取模式下复制相关的3个MySQL线程

* **slave上的I/O线程**：向master请求数据
* **master上的Binlog Dump线程**：读取binlog事件并把数据发送给slave的I/O线程
* **slave上的SQL线程**：读取中继日志并执行，更新数据库

## 相关监控命令
```
show processlist      # 查看MySQL进程信息，包括3个同步线程的当前状态
show master status    # 查看master配置及当前复制信息
show slave status     # 查看slave配置及当前复制信息
```



# MySQL异步

MySQL异步是指**将MySQL连接事件驱动化**，这样就变成了非阻塞IO。数据库操作并不会阻塞进程，**在MySQL-Server返回结果时再执行对应的逻辑**。

**注意点**：

* 异步MySQL并没有节省SQL执行的时间
* 一个MySQL连接同时只能执行1个SQL，如果异步MySQL存在并发那么必须创建多个MySQL连接
* 异步回调程序中，异步MySQL并没有提升性能。**异步最大的好处是可以高并发**，如果并发1万个请求，那么就需要建立1万个MySQL连接，这会给MySQL-Server带来巨大的压力。

虽然应用层代码使用异步回调避免了自身的阻塞，实际上真正的瓶颈是数据库服务器。异步MySQL还带来了额外的编程复杂度，所以除非是特殊场景的需求，否则不建议使用异步MySQL。如果程序中坚持要使用异步，那么必须是异步MySQL+连接池的形式。超过规定的MySQL最大连接后，应当对SQL请求进行排队，而不是创建新连接，避免大量并发请求导致MySQL服务器崩溃。



# MySQL性能相关的配置参数

* **max_connecttions** ：最大连接数
* **table_cache** ：缓存打开表的数量
* **key_buffer_size** ：索引缓存大小
* **query_cache_size** ：查询缓存大小
* **sort_buffer_size** ：排序缓存大小(会将排序完的数据缓存起来)
* **read_buffer_size** ：顺序读缓存大小
* **read_rnd_buffer_size** ：某种特定顺序读缓存大小(如order by子句的查询)

查看配置方法：
```
show variables like '%max_connecttions%';
```



# MySQL的索引类型
* 普通索引：最基本的索引，没有任何限制，MyISAM中默认的BTREE类型的索引，也是大多数情况下用到的索引。

```
// 直接创建索引
CREATE INDEX index_name ON table(column(length))

// 修改表结构的方式添加索引
ALTER TABLE table_name ADD INDEX index_name ON (column(length))

// 创建表的时候同时创建索引
CREATE TABLE `table` (
  `id` int(11) NOT NULL AUTO_INCREMENT ,
  `title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,
  `time` int(10) NULL DEFAULT NULL ,
  PRIMARY KEY (`id`),
  INDEX index_name (title(length))
)

// 删除索引
DROP INDEX index_name ON table
```

* 唯一索引
  索引列的值必须唯一，但**允许有空值**（注意和主键不同）。如果是组合索引，则列值的组合必须唯一，创建方法和普通索引类似。

```
// 创建唯一索引
CREATE UNIQUE INDEX indexName ON table(column(length))

// 修改表结构
ALTER TABLE table_name ADD UNIQUE indexName ON (column(length))

// 创建表的时候直接指定
CREATE TABLE `table` (
  `id` int(11) NOT NULL AUTO_INCREMENT ,
  `title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,
  `time` int(10) NULL DEFAULT NULL ,
  PRIMARY KEY (`id`),
  UNIQUE indexName (title(length))
);
```

* 全文索引
  **仅可用于MyISAM表**。可以从CHAR、VARCHAR或TEXT列中作为CREATE TABLE语句的一部分被创建，或是随后使用ALTER TABLE或CREATE INDEX被添加。对于较大的数据集，将资料输入一个没有FULLTEXT索引的表中，然后创建索引，其速度比把资料输入现有FULLTEXT索引的速度更为快。不过对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法。 

```
// 创建表的适合添加全文索引
CREATE TABLE `table` (
  `id` int(11) NOT NULL AUTO_INCREMENT ,
  `title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,
  `time` int(10) NULL DEFAULT NULL ,
  PRIMARY KEY (`id`),
  FULLTEXT (content)
);

// 修改表结构添加全文索引
ALTER TABLE article ADD FULLTEXT index_content(content)

// 直接创建索引
CREATE FULLTEXT INDEX index_content ON article(content)
```

* 单列索引、多列索引
  多个单列索引与单个多列索引的查询效果不同，因为执行查询时，MySQL只能使用一个索引，会从多个索引中选择一个限制最为严格的索引。

* 组合索引

```
ALTER TABLE article ADD INDEX index_titme_time (title(50),time(10));
```

建立这样的组合索引，**相当于分别建立了下面两组组合索引**：

```
title,time
title
```

没有time这样的组合索引，因为MySQL组合索引执行**最左前缀匹配**，简单的理解就是只从最左面的开始组合。如：

```
SELECT * FROM article WHREE title='测试' AND time=1234567890;   # 使用title,time索引
SELECT * FROM article WHREE utitle='测试';                      # 使用title索引
SELECT * FROM article WHREE time=1234567890;                   # 未使用索引    
```

**MySQL只对以下操作符才使用索引：**

```
<、<=、=、>、>=、between、in、以及某些时候的like(不以通配符%或_开头的情形)。
```
**理论上每张表里面最多可创建16个索引**。 


# MySQL自增主键出现不连续情况的原因？如何修复？
## 造成自增主键不连续的原因

* INSERT语句不管是否成功，都会增加AUTO_INCREMENT值。
* 进行了DELETE相关操作。
* ROLLBACK相关。

## 修复自增主键，使其连续
```
INSERT INTO th_page2(site,url,title,title_index,content,tag,created_at,updated_at,deleted_at)
SELECT site,url,title,title_index,content,tag,created_at,updated_at,deleted_at FROM th_page ORDER BY tag;

DROP TABLE th_page;

ALTER TABLE th_page2 RENAME th_page;
```



# ON与WHERE有什么区别？

执行连接操作时，可先用ON先进行过滤，减少连接操作的中间结果，然后用WHERE对连接产生的结果再一次过滤。但是，如果是左/右连接，在ON条件里对主表的过滤是无效的，仍然会用到主表的所有记录，连接产生的记录如果不满足主表的过滤条件那么从表部分的数据会置为NULL。



# Redis常见配置选项

## 使用指定的配置文件启动Redis
```
./redis-server redis.conf
```

## 通过Redis命令查看、设置配置项
```
# 查看loglevel配置项
redis 127.0.0.1:6379> CONFIG GET loglevel
1) "loglevel"
2) "notice"

# 查看所有配置项
redis 127.0.0.1:6379> CONFIG GET *
1) "dbfilename"
2) "dump.rdb"
3) "requirepass"
4) ""
5) "masterauth"
6) ""
7) "unixsocket"
8) ""

# 设置loglevel项
redis 127.0.0.1:6379> CONFIG SET loglevel "notice"
OK
```


## 常见配置参数
* daemonize no          # 启用守护进程，默认不启用
* pidfile /var/run/redis.pid     # 指定pid文件，当以守护进程方式运行时用到
* port 6379             # 指定Redis监听端口
* bind 127.0.0.1        # 绑定的主机地址
* timeout 300           # 当客户端闲置指定时间后关闭连接，如果指定为0，表示关闭该功能
* loglevel verbose      # 指定日志记录级别：debug、verbose、notice、warning
* logfile stdout        # 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null
* databases 16          # 设置数据库的数量，默认数据库为0，可以使用SELECT <dbid>命令在连接上指定数据库id

* 持久化阈值设置
  指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合
```
save <seconds> <changes>
```
Redis默认配置文件中提供了三个条件：
```
save 900 1         # 900秒（15分钟）内有1个更改
save 300 10        # 300秒（5分钟）内有10个更改
save 60 10000      # 60秒内有10000个更改
```
* rdbcompression yes     # 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大

* dbfilename dump.rdb    # 指定本地数据库文件名，默认值为dump.rdb
* dir ./                 # 指定本地数据库存放目录
* slaveof <masterip> <masterport>    # 当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步
* masterauth <master-password>       # 当master服务设置了密码保护时，slav服务连接master的密码
* requirepass xxxxx      # 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH <password>命令提供密码，默认关闭
* maxclients 128         # 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息
* maxmemory <bytes>      # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区。
* appendonly no          # 指定是否在每次更新操作后进行日志记录，Redis在**默认情况下是异步的把数据写入磁盘**，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no
* appendfilename appendonly.aof      # 指定更新日志文件名，默认为appendonly.aof
* appendfsync everysec   #指定更新日志条件，共有3个可选值：
```
no        # 等操作系统进行数据缓存同步到磁盘（快） 
always    # 每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） 
everysec  # 每秒同步一次（折衷，默认值）
```
* vm-enabled no          # 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中
* vm-swap-file /tmp/redis.swap       # 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享
* vm-max-memory 0        # 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0
* vm-page-size 32        # Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不确定，就使用默认值
* vm-pages 134217728     # 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，在磁盘上每8个pages将消耗1byte的内存。
* vm-max-threads 4       # 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4
* glueoutputbuf yes      # 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启

* 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法
```
hash-max-zipmap-entries 64
hash-max-zipmap-value 512
```

* activerehashing yes    # 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）
* include /path/to/local.conf       # 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件

# OAuth2.0工作过程理解
OAuth是一个关于授权（authorization）的开放网络标准，目前的版本是2.0版。其作用就是让"客户端"（第三方应用）安全可控地获取"用户"的授权，与"服务提供商"（平台，比如微信）进行互动。
OAuth**在"客户端"与"服务提供商"之间，设置了一个授权层**（authorization layer）。"客户端"不能直接登录"服务提供商"，只能登录授权层，以此将用户与客户端区分开来。"客户端"登录授权层所用的令牌（token），与用户的密码不同。**用户可以在登录的时候，指定授权层令牌的权限范围和有效期**。"客户端"登录授权层以后，"服务提供商"根据令牌的权限范围和有效期，向"客户端"开放用户储存的资料。

## OAuth 2.0的运行流程

![image](/images/tech/net_7.png) 

客户端的授权模式（步骤B）

## OAuth 2.0的四种授权方式

### 1.授权码模式（authorization code） 

适用于有server端的应用授权，是功能最完整、流程最严密的授权模式。它的特点就是**通过客户端的后台服务器，与"服务提供商"的认证服务器进行互动**。

* （A）用户访问客户端，后者将前者导向认证服务器。
* （B）用户选择是否给予客户端授权。
* （C）假设用户给予授权，认证服务器将用户导向客户端事先指定的"重定向URI"（redirection URI），同时附上一个授权码。
* （D）客户端收到授权码，附上早先的"重定向URI"，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。
* （E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。

即：用一个URI去申请，获得用户授权后得到一个对应该URI的授权码。之后就可以用该URI+对应的授权码来获取一个令牌，之后就可以使用该令牌来通过授权层。

### 2.隐式授权（implicit） 

适用于通过客户端访问的应用授权，不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了"授权码"这个步骤，因此得名。**所有步骤在浏览器中完成**，令牌对访问者是可见的，且客户端不需要认证。

* （A）客户端将用户导向认证服务器。
* （B）用户决定是否给于客户端授权。
* （C）假设用户给予授权，认证服务器将用户导向客户端指定的"重定向URI"，并在URI的Hash部分包含了访问令牌。
* （D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。
* （E）资源服务器返回一个网页(typically an HTML document with an embedded script)，其中包含的代码可以获取Hash值中的令牌。
* （F）浏览器执行上一步获得的脚本，提取出令牌。
* （G）浏览器将令牌发给客户端（客户端就可以凭借此令牌来获取数据）。

**实例：**

其中短暂停留的那个页面的url为：
https://www.zhihu.com/oauth/callback/login/qqconn?code=680726D150FF0B9DF2EBBE2EFEEEC0D4&state=7f13b99dc94e506e69ecb9ec83296eec

页面效果：
![image](/images/tech/net_8.png)

页面代码：
![image](/images/tech/net_9.png)

### 3.密码模式（resource owner password credentials）

用户向客户端提供自己的用户名和密码。客户端使用这些信息，向"服务商提供商"索要授权。这通常用在用户对客户端高度信任的情况下。

### 4.客户端模式（client credentials）

指客户端以自己的名义，而不是以用户的名义，向"服务提供商"进行认证。**严格地说，客户端模式并不属于OAuth框架所要解决的问题**。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求"服务提供商"提供服务，其实不存在授权问题。



# IO阻塞、非阻塞、同步、异步
## 同步和异步

同步和异步是**针对应用程序和内核的交互而言**的，同步指的是用户进程触发I/O操作并等待或者轮询的去查看I/O操作是否就绪，而异步是指用户进程触发I/O操作以后便开始做自己的事情，而当I/O操作已经完成的时候会得到I/O完成的通知。

## 阻塞和非阻塞

阻塞和非阻塞是**针对于进程在访问数据的时候**，根据I/O操作的就绪状态来采取的不同方式，是一种读取或者写入函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。

## 服务器IO模型

### 阻塞式模型（blocking IO）

大部分的socket接口都是阻塞型的（ listen()、accpet()、send()、recv() 等）。阻塞型接口是指系统调用（一般是 IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。在线程被阻塞期间，线程将无法执行任何运算或响应任何的网络请求，这给多客户机、多业务逻辑的网络编程带来了挑战。
![image](/images/tech/basic_9.png)

### 多线程的服务器模型（Multi-Thread）

应对多客户机的网络应用，最简单的解决方式是在服务器端使用多线程（或多进程）。多线程（或多进程）的目的是**让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接**。但是如果要同时响应成千上万路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率。
在多线程的基础上，可以考虑使用线程池或连接池，线程池旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。连接池维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统。

### 非阻塞式模型（Non-blocking IO）

相比于阻塞型接口的显著差异在于，在被调用之后立即返回。
![image](/images/tech/basic_10.png)
需要应用程序调用许多次来等待操作完成。这可能效率不高，因为在很多情况下，当内核执行这个命令时，应用程序必须要进行**忙碌等待**，直到数据可用为止。
另一个问题，在循环调用非阻塞IO的时候，将大幅度占用CPU，所以一般使用select等来检测是否可以操作。

### 多路复用IO（IO multiplexing）
支持I/O复用的系统调用有select、poll、epoll、kqueue等。使用select返回后，仍然需要轮询再检测每个socket的状态（读、写），这样的轮询检测在大量连接下也是效率不高的。因为**当需要探测的句柄值较大时，select () 接口本身需要消耗大量时间去轮询各个句柄**。
很多操作系统提供了更为高效的接口，如Linux 提供了`epoll`，BSD提供了`kqueue`，Solaris提供了`/dev/poll `…。如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐，能显著**提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率**。
![image](/images/tech/basic_11.png)

### 使用事件驱动库libevent的服务器模型
libevent是一个**事件触发的**网络库，适用于Windows、Linux、BSD等多种平台，**内部使用select、epoll、kqueue、IOCP等系统调用管理事件机制**。
libevent库提供一种事件机制，它作为底层网络后端的包装器。事件系统让为连接添加处理函数变得非常简便，同时降低了底层IO复杂性。这是libevent系统的核心。
创建libevent服务器的基本方法是，注册当发生某一操作（比如接受来自客户端的连接）时应该执行的函数，然后调用主事件循环event_dispatch()。执行过程的控制现在由libevent系统处理。注册事件和将调用的函数之后，事件系统开始自治；在应用程序运行时，可以在事件队列中添加（注册）或 删除（取消注册）事件。事件注册非常方便，可以通过它添加新事件以处理新打开的连接，从而构建灵活的网络处理系统。

### 信号驱动IO模型（Signal-driven IO）
让内核在描述符就绪时发送SIGIO信号通知应用程序。
![image](/images/tech/basic_12.png)

### 异步IO模型（asynchronous IO）
告知内核启动某个操作，并让内核在整个操作（包括将数据从内核复制到用户的缓冲区）完成后通知用户。这种模型与信号驱动模型的主要区别在于：信号驱动式I/O是由内核通知何时可以启动一个I/O操作，而异步I/O模型是由内核通知I/O操作何时完成。
![image](/images/tech/basic_13.png)

## 异步IO与同步IO的区别
A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;
An asynchronous I/O operation does not cause the requesting process to be blocked; 
两者的区别就在于synchronous IO做IO operation的时候会将process阻塞。按照这个定义阻塞、非阻塞、IO多路复用其实都属于同步IO。

## 异步IO与非阻塞IO的区别

在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用`recvfrom`来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程**将整个IO操作（分为两步：准备数据、将数据从内核复制到用户空间）交给了他人（kernel）完成，然后他人做完后发信号通知**。在此期间，用户进程**不需要去检查IO操作的状态，也不需要主动的去拷贝数据**。

# Redis HyperLogLog理解

## 基数

如数据集 {1, 3, 5, 7, 5, 7, 8}，那么这个数据集的基数集为 {1, 3, 5 ,7, 8}，基数（不重复元素个数）为5。 

基数估计：在误差可接受的范围内，快速计算基数。

Redis HyperLogLog是**用来做基数统计的算法**，HyperLogLog的优点是，**在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的**。

因为HyperLogLog只会根据输入元素来计算基数，而不会储存输入元素本身，所以HyperLogLog不能像集合那样，返回输入的各个元素。

**例：**
```
redis 127.0.0.1:6379> PFADD w3ckey "redis"
1) (integer) 1
redis 127.0.0.1:6379> PFADD w3ckey "mongodb"
1) (integer) 1
redis 127.0.0.1:6379> PFADD w3ckey "mysql"
1) (integer) 1
redis 127.0.0.1:6379> PFCOUNT w3ckey
(integer) 3
```

## 基本命令

* PFADD key element [element ...]                        # 添加指定元素到HyperLogLog中
* PFCOUNT key [key ...]                                           # 返回给定HyperLogLog的基数估算值
* PFMERGE destkey sourcekey [sourcekey ...]     # 将多个HyperLogLog合并为一个HyperLogLog




# HTTP协议缓存协商机制相关的6个HTTP头

HTTP缓存协商机制基于6个HTTP头信息进行，动态内容本身并不受浏览器缓存机制的排斥，**只要HTTP头信息中包含相应的缓存协商信息，动态内容一样可以被浏览器缓存**。不过对于POST类型的请求，浏览器一般不启用本地缓存。除了浏览器缓存，HTTP缓存协商机制同样适用于HTTP缓存代理服务器。

主要涉及以下6个HTTP Header：
`Expires`

`Cache-Control`

`Last-Modified`、`If-Modified-Since`

`ETag`、`If-None-Match`。

**Expires/Cache-Control**是控制浏览器**是否直接从浏览器缓存取数据还是重新发请求到服务器取数据**。只是Cache-Control比Expires可以控制的多一些，而且**Cache-Control会重写Expires的规则**。Cache-Control常见的取值有private、no-cache、max-age、must-revalidate等。如果指定Cache-Control的值为private、no-cache、must-revalidate，那么打开新窗口访问时都会重新访问服务器。而如果指定了max-age值，那么**在此值内的时间里就不会重新访问服务器**，例如：`Cache-control: max-age=5`表示当访问此网页后的5秒内再次访问不会去服务器。

**Last-Modified/If-Modified-Since**和**ETag/If-None-Match**是**浏览器发送请求到服务器后判断文件是否已经修改过**，如果没有修改过就只发送一个304回给浏览器，告诉浏览器直接从自己本地的缓存取数据；如果修改过那就整个数据重新发给浏览器。

## Expires和Cache-Control max-age的区别与联系

1. Expires在HTTP/1.0中已经定义，Cache-Control:max-age在HTTP/1.1中才有定义。
2. Expires指定一个**绝对的过期时间**(GMT格式)，这么做会导致至少2个问题：
* 客户端和服务器时间不同步导致Expires的配置出现问题。
* 很容易在配置后忘记具体的过期时间，导致过期来临出现浪涌现象；（而Cache-Control:max-age指定的是从文档被访问后的存活时间，这个时间是个相对值，相对的是文档第一次被请求时服务器记录的请求时间。
3. Expires指定的时间可以是相对文件的最后访问时间或者修改时间，而max-age相对对的是文档的请求时间。
4. 在Apache中，max-age是根据Expires的时间来计算出来的max-age = expires- request_time:(mod_expires.c)

目前主流的浏览器都将HTTP/1.1作为首选，所以当HTTP响应头中同时含有Expires和Cache-Control时，浏览器会优先考虑Cache-Control。


## Last-Modified/If-Modified-Since和ETag/If-None-Match工作方式

1. 浏览器把缓存文件的最后修改时间通过If-Modified-Since来告诉Web服务器（浏览器缓存里存储的不只是网页文件，还有服务器发过来的该文件的最后服务器修改时间）。服务器会把这个时间与服务器上实际文件的最后修改时间进行比较。如果时间一致，那么返回HTTP状态码304（但不返回文件内容），客户端接到之后，就直接把本地缓存文件显示到浏览器中。如果时间不一致，就返回HTTP状态码200和新的文件内容，客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示到浏览器中（当文件发生改变，或者第一次访问时，服务器返回的HTTP头标签中有Last-Modified，告诉客户端页面的最后修改时间）。

2. 浏览器把缓存文件的ETag，通过If-None-Match，来告诉Web服务器。思路与第一种类似。

**一个例子**
Request Headers
```
Host localhost
User-Agent Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.8.1.16) Gecko/20080702 Firefox/2.0.0.16
Accept text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5
...
If-Modified-Since Tue, 19 Aug 2008 06:49:35GMT
If-None-Match 7936caeeaf6aee6ff8834b381618b513
Cache-Control max-age=0
```

Response Headers
```
Date Tue, 19 Aug 2008 06:50:19 GMT
...
Expires Tue, 19 Aug 2008 07:00:19 GMT
Last-Modified Tue, 19 Aug 2008 06:49:35GMT
Etag 7936caeeaf6aee6ff8834b381618b513
```

对应以上两组缓存控制Header，按F5刷新浏览器和在地址栏里输入网址然后回车。这两个行为是不一样的。**按F5刷新浏览器，浏览器会去Web服务器验证缓存。如果是在地址栏输入网址然后回车，浏览器会直接使用有效的缓存，而不会发http request去服务器验证缓存，这种情况叫做`缓存命中`**。

Cache-Control: public 指可以`公有缓存`，可以是数千名用户共享的。
Cache-Control: private 指只支持`私有缓存`，私有缓存是单个用户专用的。
此外，针对不同的Cache-Control值，对浏览器执行不同的操作，其缓存访问行为也不一样，这些操作包括：打开新窗口、在地址栏回车、按后退按钮、按刷新按钮。

## Last-Modified/If-Modified-Since和ETag/If-None-Match工作方式的区别
```
<?php
  header('Last-Modified:' . gmdate('D, d M Y H:i:s') . ' GMT');
  echo time();
?>
```

此时再通过浏览器请求该动态文件，HTTP响应中将会添加一个头信息：
```
Last-Modified:Fri, 20 Mar 2009 07:53:02 GMT
```

对于带有`Last-Modified`的响应，浏览器会对文件进行缓存，并打上一些标记，下次再发出请求时会带上如下的HTTP头信息：
```
If-Modified-Since:Fri, 20 Mar 2009 07:53:02 GMT
```

如果没有修改，服务器会返回304信息：
```
HTTP/1.1 304 Not Modified
...
```
意味着浏览器可以直接使用本地缓存的内容。

**使用基于最后修改时间的缓存协商存在一些缺点**：
1. 很可能文件内容没有变化，而只是时间被更新，此时浏览器仍然会获取全部内容。
2. 当使用多台机器实现负载均衡时，用户请求会在多台机器之间轮询，而不同机器上的相同文件最后修改时间很难保持一致，可能导致用户的请求每次切换到新的服务器时就需要重新获取所有内容。

比如服务器返回如下带ETag的响应：
```
ETag:"74123-b-938fny4nfi8"
```

浏览器在下次请求该内容时会在HTTP头中添加如下信息：
```
If-None-Match:"74123-b-938fny4nfi8"
```
如果相同的话，服务器返回304。
Web服务器可以自由定义ETag的格式和计算方法。



# GET和POST在TCP层的区别

**GET产生一个TCP数据包，POST产生两个TCP数据包**：
对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；
而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。



# 面向对象编程应该遵守的几个原则

## 依赖倒换原则
要针对接口编程，不要对实现编程：
* 1.高层模块不应该依赖于低层模块。
* 2.抽象不应该依赖细节，细节应该依赖抽象。

![image](https://github.com/woojean/woojean.github.io/blob/master/assets/images/dm_1.png)


## 单一职责原则
就一个类而言，应该仅有一个引起它变化的原因。如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者抑制这个类完成其他职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭受到意想不到的破坏。比如设计游戏显示区域，将绝对坐标改成相对坐标，实现程序逻辑和界面的分离。


## 开放-封闭原则
软件实体（类、模块、函数等等）应该可以扩展，但是不可修改。
面对需求，对程序的改动是通过增加新代码进行的，而不是更改现有的代码。
最初编写代码时，假设变化不会发生，当变化发生时，就创建抽象来隔离以后发生的同类变化。
开发人员应该仅对程序中呈现出频繁变化的那部分作出抽象，然而对于程序中的每个部分都刻意地进行抽象同样不是一个好主意。


## 迪米特法则
如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。在类的结构设计上，每一个类都应当尽量降低成员的访问权限。其根本思想是强调了类之间的松耦合，类之间的耦合越弱，越有利于复用，一个处在弱耦合的类被修改，不会对有关系的类造成波及。


## 里氏代换原则
一个软件实体，如果使用的是一个父类的话，那么一定适用于其子类，而且它觉察不出父类对象和子类对象的区别。正是由于子类型的可替换性才使得使用父类类型的模块在无需修改的情况下就可以扩展。



# 秒杀系统性能优化思路

将请求尽量拦截在系统上游，并且充分利用缓存。由上游至低层优化如下：

## 1.前端（浏览器、APP）

控制实际往后端发送请求的数量，如用户点击“查询”后，将按钮置灰，禁止用户在短时间内重复提交。

## 2.站点层（访问后端数据，拼写html返回）

**对uid进行请求计数和去重，比如5秒内只准透过一个请求**（可以使用redis设置过期时间实现）。缺点是当有多台机器时（此时相当于5s内限制n个访问），数据可能不准（脏读,但数据库层面真实数据是没问题的）。
假设有海量真实的对站点层的请求，可以通过增加机器来扩容，实在不行只能抛弃部分请求（返回稍后再试），原则是要保护系统，不能让所有用户都失败；

## 3.服务层（提供数据访问）

对于读请求，使用缓存。
对于写请求，使用请求队列（队列成本很低），每次只透有限的写请求（如总票数）去数据层，如果均成功，再放下一批。可以不用统一一个队列，这样的话每个服务透过更少量的请求（总票数/服务个数），这样简单。统一一个队列又复杂了。对于失败的处理无需重放，返回用户查询失败或者下单失败，架构设计原则之一是fail fast。

## 4.数据层（数据库、缓存）

经过以上步骤，到数据库层的请求已经有限。

此外还可以做一些业务规则上的优化，如：12306分时分段售票、数据粒度优化（如只展示有、无，而不是具体的数量）、业务逻辑异步（先创建订单，但是状态为未支付，如果超时仍未支付，则恢复库存）。



# 依赖注入、控制反转

IoC（Inversion of Control）控制反转
DI（Dependency Injection）依赖注入

**DI是IoC的一种具体实现**，另一种主要的实现方式是服务定位器（Service Locator）。

没有IoC的时候，常规的A类使用C类的示意图：
 ![image](/images/tech/img_1.png)

有IoC的时候，A类不再主动去创建C，而是被动等待，等待IoC的容器获取一个C的实例，然后反向地注入到A类中。
 ![image](/images/tech/img_2.png)


# Nginx有哪些内置的全局变量？
* $args                    请求中的参数;
* $content_length          HTTP请求信息里的"Content-Length";
* $content_type            请求信息里的"Content-Type";
* $document_root           针对当前请求的根路径设置值;
* $document_uri            与$uri相同;
* $host                    http请求的域名
* $http_user_agent         客户端agent信息;
* $http_cookie             客户端cookie信息;
* $limit_rate              对连接速率的限制;
* $request_body_file       客户端请求主体信息的临时文件名;
* $request_method          请求的方法，比如"GET"、"POST"等;
* $remote_addr             客户端地址;
* $remote_port             客户端端口号;
* $remote_user             客户端用户名，认证用;
* $request_filename        当前请求的文件路径名;
* $request_body_file       客户端请求主体的临时文件名;
* $request_uri             包含请求参数的原始URI，不包含主机名，如："/foo/bar.php?arg=baz";
* $query_string            与$args相同;
* $scheme                  所用的协议，比如http或者是https;
* $server_addr             服务器地址，如果没有用listen指明服务器地址，使用这个变量将发起一次系统调用以取得地址(造成资源浪费);
* $server_name             请求到达的服务器名;
* $server_port             请求到达的服务器端口号;
* $uri                     不带请求参数的当前URI，$uri不包含主机名，如"/foo/bar.html";
* $fastcgi_script_name     这个变量等于一个以斜线结尾的请求URI加上fastcgi_index给定的参数。可以用这个变量代替SCRIPT_FILENAME 和PATH_TRANSLATED，以确定php脚本的名称。
  如请求"/info/": 
```
fastcgi_index index.php;  
fastcgi_param SCRIPT_FILENAME /home/www/scripts/php$fastcgi_script_name;
```
SCRIPT_FILENAME等于`/home/www/scripts/php/info/index.php`



# Nginx fastcgi_index配置的作用

语法：
```
fastcgi_index file 
```
如果URI以斜线结尾，文件名将追加到URI后面，这个值将存储在变量`$fastcgi_script_name`中。

**例如：**
```
fastcgi_index  index.php;
fastcgi_param  SCRIPT_FILENAME  /home/www/scripts/php$fastcgi_script_name;
```
请求`/page.php`时，SCRIPT_FILENAME将被设置为`/home/www/scripts/php/page.php`，但是请求`/`则为`/home/www/scripts/php/index.php`。



# Nginx fastcgi_param配置理解

fastcgi_param用于定义一些fastcgi模块的环境变量：
```
# 脚本文件请求的路径
fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;

# 请求的参数，如?app=123
fastcgi_param QUERY_STRING $query_string;

# 请求的动作(GET,POST)			
fastcgi_param REQUEST_METHOD $request_method;

# 请求头中的Content-Type字段
fastcgi_param CONTENT_TYPE $content_type;

# 请求头中的Content-length字段
fastcgi_param CONTENT_LENGTH $content_length;

# 脚本名称 
fastcgi_param SCRIPT_NAME $fastcgi_script_name; 

# 请求的地址（不带参数）
fastcgi_param REQUEST_URI $request_uri;

# 与$uri相同
fastcgi_param DOCUMENT_URI $document_uri; 

# 网站的根目录，在server配置中root指令中指定的值
fastcgi_param DOCUMENT_ROOT $document_root;  

# 请求使用的协议，通常是HTTP/1.0或HTTP/1.1
fastcgi_param SERVER_PROTOCOL $server_protocol;

# cgi 版本
fastcgi_param GATEWAY_INTERFACE CGI/1.1;

# nginx 版本号，可修改、隐藏
fastcgi_param SERVER_SOFTWARE nginx/$nginx_version;

# 客户端IP
fastcgi_param REMOTE_ADDR $remote_addr;

# 客户端端口
fastcgi_param REMOTE_PORT $remote_port; 

# 服务器IP地址
fastcgi_param SERVER_ADDR $server_addr;

# 服务器端口
fastcgi_param SERVER_PORT $server_port;

# 服务器名，域名在server配置中指定的server_name
fastcgi_param SERVER_NAME $server_name;

# 可自定义变量
# fastcgi_param PATH_INFO $path_info;

# PHP only, required if PHP was built with --enable-force-cgi-redirect
# fastcgi_param REDIRECT_STATUS 200;
```

## 在php可打印出上面的服务环境变量
```php
echo $_SERVER['REMOTE_ADDR']
```

# Nginx fastcgi_pass配置理解
指定FastCGI服务器监听端口与地址。
* 直接使用IP地址和端口号指定
```
fastcgi_pass localhost:9000;
```

* 使用Unix Socket指定
```
fastcgi_pass unix:/tmp/fastcgi.socket;
```

* 使用upstream指定
```
upstream backend  {  
  server   localhost:1234;
} 
fastcgi_pass backend;
```



# Nginx fastcgi_read_timeout配置理解

前端FastCGI服务器的响应超时时间，如果有一些直到它们运行完才有输出的长时间运行的FastCGI进程，或者在错误日志中出现前端服务器响应超时错误，可能需要调整这个值。



# Nginx支持的IO模型有哪些？

Nginx支持如下处理连接的方法（I/O复用方法），这些方法可以通过use指令指定：
* select：如果当前平台没有更有效的方法，它是编译时默认的方法。可以使用配置参数–with-select_module和–without-select_module来启用或禁用这个模块。
* poll：如果当前平台没有更有效的方法，它是编译时默认的方法。可以使用配置参数–with-poll_module和–without-poll_module来启用或禁用这个模块。
* kqueue：高效的方法，使用于FreeBSD 4.1+、 OpenBSD 2.9+、NetBSD 2.0和MacOS X。使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。
* epoll：高效的方法，使用于Linux内核2.6版本及以后的系统。在某些发行版本中，如SuSE 8.2, 有让2.4版本的内核支持epoll的补丁。
* rtsig：可执行的实时信号，使用于Linux内核版本2.2.19以后的系统。默认情况下整个系统中不能出现大于1024个POSIX实时(排队)信号。这种情况对于高负载的服务器来说是低效的；所以有必要通过调节内核参数 /proc/sys/kernel/rtsig-max来增加队列的大小。可是从Linux内核版本2.6.6-mm2开始， 这个参数就不再使用了，并且对于每个进程有一个独立的信号队列，这个队列的大小可以用RLIMIT_SIGPENDING 参数调节。当这个队列过于拥塞，nginx就放弃它并且开始使用poll方法来处理连接直到恢复正常。
* /dev/poll：高效的方法，使用于Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+.
* eventport：高效的方法，使用于Solaris 10。
  在linux下面，只有epoll是高效的方法。




# Nginx与php-fpm配合工作的流程

*  （1）FastCGI进程管理器php-fpm自身初始化，启动主进程php-fpm和启动start_servers个CGI 子进程。

主进程php-fpm主要是管理fastcgi子进程，监听9000端口。
fastcgi子进程等待来自Web Server的连接。

* （2）当客户端请求到达Nginx时，Nginx通过location指令，将所有以php为后缀的文件都交给127.0.0.1:9000来处理。
* （3）FastCGI进程管理器PHP-FPM选择并连接到一个子进程CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程。
* （4）FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。
* （5）FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。




# Nginx的配置理解

nginx配置文件主要分为六个区域：

* main
  控制子进程的所属用户/用户组、派生子进程数、错误日志位置/级别、pid位置、子进程优先级、进程对应cpu、进程能够打开的文件描述符数目等

* events
  控制nginx处理连接的方式

* http
* sever
* location
* upstream

**实例：**
```
# 运行用户
user www-data;

# 启动进程数,通常设置成和cpu的数量相等
worker_processes 1;

# 全局错误日志
error_log /var/log/nginx/error.log;

# PID文件
pid /var/run/nginx.pid;

events {
  # 使用epoll多路复用模式
  use epoll;   

  # 单个后台worker process进程的最大并发链接数
  worker_connections  1024;
  # multi_accept on; 
}

http {
  # 设定mime类型,类型由mime.type文件定义
  include       /etc/nginx/mime.types;

  # 1 octet = 8 bit
  default_type  application/octet-stream;

  # 设定访问日志
  access_log    /var/log/nginx/access.log;

  # sendfile指令指定nginx是否调用sendfile函数（zero copy方式）来输出文件，对于普通应用，必须设为on,如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.
  sendfile        on;

  # 在一个数据包里发送所有头文件，而不一个接一个的发送
  #tcp_nopush     on;

  # 连接超时时间
  keepalive_timeout  65;

  # 作用于socket参数TCP_NODELAY，禁用nagle算法，也即不缓存数据
  tcp_nodelay        on;
    
  # 开启gzip压缩
  gzip  on;
  gzip_disable "MSIE [1-6]\.(?!.*SV1)";
 
  # 设定请求缓冲
  client_header_buffer_size    1k;
  large_client_header_buffers  44k;

  include /etc/nginx/conf.d/*.conf;
  include /etc/nginx/sites-enabled/*;

  # 设定负载均衡的服务器列表
  upstream mysvr {
    # weigth参数表示权值，权值越高被分配到的几率越大
    # 本机上的Squid开启3128端口
    server 192.168.8.1:3128 weight=5;
    server 192.168.8.2:80 weight=1;
    server 192.168.8.3:80 weight=6;
  }
 
server {
  # 侦听80端口
  listen 80;

  # 定义使用www.xx.com访问
  server_name  www.xx.com;

  # 设定本虚拟主机的访问日志
  access_log  logs/www.xx.com.access.log  main;

  # 默认请求
  location / {
    # 定义服务器的默认网站根目录位置
    root   /root;      	

    # 定义首页索引文件的名称
    index index.php index.html index.htm;  

    fastcgi_pass  localhost:9000;
      fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name; 
      include /etc/nginx/fastcgi_params;  
    }

    # 定义错误提示页面
    error_page   500 502 503 504 /50x.html;  
      location = /50x.html {
      root   /root;
    }

    # 静态文件，nginx自己处理
    location ~ ^/(images|javascript|js|css|flash|media|static)/ {
      root /var/www/virtual/htdocs;
      
      # 过期时间30天
      expires 30d;
    }

    # PHP脚本请求全部转发到FastCGI处理，使用FastCGI默认配置
    location ~ \.php$ {
      root /root;
      fastcgi_pass 127.0.0.1:9000;
      fastcgi_index index.php;
      fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;
      include fastcgi_params;
    }

    # 设定查看Nginx状态的地址
    location /NginxStatus {
      stub_status on;
      access_log on;
      auth_basic "NginxStatus";
      auth_basic_user_file conf/htpasswd;
    }

    # 禁止访问 .htxxx 文件
    location ~ /\.ht {
      deny all;
    }
  }
}
```



# Nginx反向代理提高性能的理解

对于后端是动态服务来说，比如Java和PHP。这类服务器（如JBoss和PHP-FPM）的IO处理能力往往不高。**Nginx有个好处是它会把Request在读取完整之前buffer住，这样交给后端的就是一个完整的HTTP请求**，从而提高后端的效率，而不是断断续续的传递（互联网上连接速度一般比较慢）。同样，Nginx**也可以把response给buffer住，同样也是减轻后端的压力**。



# Nginx rewrite与Location的比较

## rewrite

使用Nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位**实现url重写以及重定向**。rewrite只能放在server{},location{},if{}中，并且**只能对域名后边的除去传递的参数外的字符串起作用**。如，`http://demo.com/a/we/index.php?id=1&u=str` 只对`/a/we/index.php`重写。
如果想对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。

**Rewrite标志位**

* last  相当于Apache的[L]标记，表示完成rewrite
* break  停止执行当前虚拟主机的后续rewrite指令集
* redirect 返回302临时重定向，地址栏会显示跳转后的地址
* permanent 返回301永久重定向，地址栏会显示跳转后的地址

**Rewrite实例**
```
// 应用于Server
server {
  listen 80;
  server_name demo.com;
  index index.html index.php;
  root html;
  if ($http_host !~ “^star\.igrow\.cn$&quot {
    rewrite ^(.*) http://star.igrow.cn$1 redirect;
  }
}

// 防盗链
location ~* \.(gif|jpg|swf)$ {
  valid_referers none blocked start.igrow.cn sta.igrow.cn;
  if ($invalid_referer) {
    rewrite ^/ http://$host/logo.png;
  }
}

// 根据文件类型设置过期时间
location ~* \.(js|css|jpg|jpeg|gif|png|swf)$ {
  if (-f $request_filename) {
    expires 1h;
    break;
  }
}

// 禁止访问某个目录
location ~* \.(txt|doc)${
root /data/www/wwwroot/linuxtone/test;
deny all;
}
```
## rewrite和location的比较

rewrite和location都能实现跳转，主要区别在于**rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器**。很多情况下rewrite也会写在location里，它们的执行顺序是：

* （1）执行server块的rewrite指令
* （2）执行location匹配
* （3）执行选定的location中的rewrite指令

如果其中某步URI被重写，则重新循环执行（1）~（3），直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。

正则匹配会覆盖普通匹配，**location的执行逻辑跟location的编辑顺序无关**。

**location语法格式**：

```
location [=|~|~*|^~|@] /uri/ { … }
```

* = 表示精确匹配
* ~  区分大小写匹配
* ~* 不区分大小写匹配
* !~ 区分大小写不匹配
* !~* 不区分大小写不匹配
* ^ 以什么开头的匹配
* $ 以什么结尾的匹配
* ^~ 表示uri以某个常规字符串开头，不是正则匹配，优先级高于正则
* / 通用匹配,如果没有其它匹配,任何请求都会匹配到
* 代表任意字符
* . 匹配除换行符以外的任意字符
* ? 重复0次或1次
* \+ 重复1次或更多次
* \* 重复0次或更多次
* \d 匹配数字
* {n}重复n次
* {n,}重复n次或更多次
* [c]匹配单个字符c
* [a-z]匹配a-z小写字母的任意一个
* \转义字符
* -f和!-f判断是否存在文件
* -d和!-d判断是否存在目录
* -e和!-e判断是否存在文件或目录
* -x和!-x判断文件是否可执行

**实际使用中一般至少有三个匹配规则定义：**
* 直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理。这里是直接转发给后端应用服务器了，也可以是一个静态首页。
```
location = / {
  proxy_pass http://tomcat:8080/index
}
```

* 处理静态文件的请求，这是nginx作为http服务器的强项。有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用。
```
location ^~ /static/ {
  root /webroot/static/;
}

location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ {  
  root /webroot/res/;
}
```
* 通用规则，用来转发动态请求到后端应用服务器非静态文件请求就默认是动态请求
```
location / {
  proxy_pass http://tomcat:8080/
}
```

# 如何使用Nginx实现负载均衡和反向代理？

设定http服务器，利用它的反向代理功能提供负载均衡支持

```
http {
  # 设定mime类型,类型由mime.type文件定义
  include       /etc/nginx/mime.types;
  default_type  application/octet-stream;

  # 设定日志格式
  access_log    /var/log/nginx/access.log;

  # 其他配置，略

  # 设定负载均衡的服务器列表
  upstream mysvr {
    # weigth参数表示权值，权值越高被分配到的几率越大
    # 本机上的Squid开启3128端口
    server 192.168.8.1x:3128 weight=5;
      server 192.168.8.2x:80 weight=1;
      server 192.168.8.3x:80 weight=6;
    }

  upstream mysvr2 {
    # weigth参数表示权值，权值越高被分配到的几率越大
    server 192.168.8.x:80  weight=1;
    server 192.168.8.x:80  weight=6;
  }

  # 第一个虚拟服务器
  server {
     # 侦听192.168.8.x的80端口
    listen 80;
    server_name  192.168.8.x;

    # 对aspx后缀的进行负载均衡请求
    # 定义服务器的默认网站根目录位置
    location ~ .*\.aspx$ {
      # 定义服务器的默认网站根目录位置
      root   /root;

      # 定义首页索引文件的名称
      index index.php index.html index.htm;   

      # 请求转向mysvr定义的服务器列表
      proxy_pass  http://mysvr ;

      # 反向代理的配置
      proxy_redirect off;

      # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

      # 允许客户端请求的最大单文件字节数
      client_max_body_size 10m;

      # 缓冲区代理缓冲用户端请求的最大字节数
      client_body_buffer_size 128k;

      # nginx跟后端服务器连接超时时间(代理连接超时)
      proxy_connect_timeout 90;

      # 后端服务器数据回传时间(代理发送超时)
      proxy_send_timeout 90;

      # 连接成功后，后端服务器响应时间(代理接收超时)
      proxy_read_timeout 90;

      # 设置代理服务器（nginx）保存用户头信息的缓冲区大小
      proxy_buffer_size 4k;    

      # proxy_buffers缓冲区，网页平均在32k以下的话，这样设置
      proxy_buffers 4 32k;    

      # 高负荷下缓冲大小（proxy_buffers*2）
      proxy_busy_buffers_size 64k;    

      # 设定缓存文件夹大小，大于这个值，将从upstream服务器传
      proxy_temp_file_write_size 64k;  
    }
  }
}
```

# 服务器出现大量TIME_WAIT和CLOSE_WAIT的可能原因是什么？

## 查看当前服务器网络连接状态
```
netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
```
输出：
```
TIME_WAIT 814
CLOSE_WAIT 1
FIN_WAIT1 1
ESTABLISHED 634
SYN_RECV 2
LAST_ACK 1
```

常用的三个状态是：
* ESTABLISHED 表示正在通信
* TIME_WAIT 表示主动关闭
* CLOSE_WAIT 表示被动关闭
  ![image](/images/tech/net_12.png)

如果服务器出了异常，百分之八九十都是下面两种情况：
* 服务器保持了大量TIME_WAIT状态
* 服务器保持了大量CLOSE_WAIT状态
  因为Linux分配给一个用户的文件句柄是有限的，而TIME_WAIT和CLOSE_WAIT两种状态如果一直被保持，那么意味着对应数目的通道就一直被占着，一旦达到句柄数上限，新的请求就无法被处理了，接着就是大量`Too Many Open Files`异常。

## 服务器保持了大量TIME_WAIT状态的原因
TIME_WAIT是主动关闭连接的一方保持的状态，对于爬虫服务器来说他本身就是客户端，在完成一个爬取任务之后，就会发起主动关闭连接，从而进入TIME_WAIT的状态，然后在保持这个状态2MSL（max segment lifetime）时间之后，彻底关闭回收资源。
而对于HTTP的交互跟上面画的那个图是不一样的，**关闭连接的不是客户端，而是服务器**，所以web服务器也是会出现大量的TIME_WAIT的情况的。解决思路很简单，就是让服务器能够快速回收和重用那些TIME_WAIT的资源，通过修改`/etc/sysctl.conf`文件实现：
```
net.ipv4.tcp_tw_reuse = 1    # 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭  
net.ipv4.tcp_tw_recycle = 1  # 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭  
```

## 服务器保持了大量CLOSE_WAIT状态的原因
TIME_WAIT状态可以通过优化服务器参数得到解决，因为发生TIME_WAIT的情况是服务器自己可控的，要么就是对方连接的异常，要么就是自己没有迅速回收资源，总之不是由于自己程序错误导致的。
如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在**对方关闭连接之后服务器程序自己没有进一步发出ack信号**。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。
如：服务器A是一台爬虫服务器，它使用简单的HttpClient去请求资源服务器B上面的apache获取文件资源，正常情况下，如果请求成功，那么在抓取完资源后，服务器A会主动发出关闭连接的请求，这个时候就是主动关闭连接，服务器A的连接状态我们可以看到是TIME_WAIT。如果一旦发生异常呢？假设 请求的资源服务器B上并不存在，那么这个时候就会由服务器B发出关闭连接的请求，服务器A就是被动的关闭了连接，如果服务器A被动关闭连接之后程序员忘了 让HttpClient释放连接，那就会造成CLOSE_WAIT的状态了。

# Redis中几种实现锁的方式的比较
## 使用INCRE

```c
$value = $redis->get($lock); 
if($value < 1 ){
  $redis->incr($lock,1);
  // ...
  $redis->decr($lock,1);
}
```

## 使用WATCH

```c
// 被WATCH的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在EXEC执行之前被修改了，那么整个事务都会被取消
WATCH mykey
  $val = GET mykey   // 乐观锁
  $val = $val + 1
MULTI
  SET mykey $val
EXEC
```

## 使用SETNX

是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置。

```c
// 缓存过期时通过SetNX获取锁，如果成功了就更新缓存，然后删除锁
$ok = $redis->setNX($key, $value);
if ($ok) {
  $cache->update();
  $redis->del($key);
}
```
存在问题：如果请求执行因为某些原因意外退出了，导致创建了锁但是没有删除锁，那么这个锁将一直存在，以至于以后缓存再也得不到更新。

因此需要给锁加一个过期时间以防不测。
```php
// 加锁
$redis->multi();
$redis->setNX($key, $value);
$redis->expire($key, $ttl);
$redis->exec();
```
存在问题：当多个请求到达时，虽然只有一个请求的SetNX可以成功，但是任何一个请求的Expire却都可以成功，如此就意味着即便获取不到锁，也可以刷新过期时间，如果请求比较密集的话，那么过期时间会一直被刷新，导致锁一直有效。

从 2.6.12 起，SET涵盖了SETEX的功能，并且SET本身已经包含了设置过期时间的功能：
```php
$ok = $redis->set($key, $value, array('nx', 'ex' => $ttl));
if ($ok) {
  $cache->update();
  $redis->del($key);
}
```
